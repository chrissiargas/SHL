Found Data
{'accBagSize': 3,
 'accBagStride': 400,
 'accDuration': 1200,
 'accStride': 1200,
 'bagging': True,
 'day': 'all',
 'decimateTime': False,
 'dropnan': True,
 'dropnull': False,
 'dynamicWindow': True,
 'gpsSignal': False,
 'hardLabelling': False,
 'interpolateGaps': 3,
 'interpolationThreshold': True,
 'labelPosition': None,
 'labellingThreshold': None,
 'locBagSize': 1,
 'locBagStride': 1,
 'locDuration': 12,
 'locPosition': None,
 'locSampling': 'hop',
 'locStride': 1,
 'overlap': True,
 'pairThreshold': 30000,
 'path': 'E:\\SHL\\',
 'percentageThreshold': 0.6,
 'position': 'all',
 'randomStride': False,
 'sampling': 'decimation',
 'smpl_acc_period': 0.05,
 'smpl_loc_period': 60,
 'src_path': 'E:\\SHL\\srcData\\',
 'strideRange': [200, 600],
 'threshold': 10000,
 'useAccuracy': True,
 'user': 'all'}

{'FFT': False,
 'accBagPivot': None,
 'accBagSize': 3,
 'accEpochs': 5,
 'acc_fusion': 'Frequency',
 'acc_model': 'CNN',
 'acc_norm_aug_params': [],
 'acc_norm_augmentation': [],
 'acc_signals': ['Acc_x', 'Acc_y', 'Acc_z', 'Acc_norm'],
 'acc_xyz_aug_params': [],
 'acc_xyz_augmentation': [],
 'bagStride': 1,
 'classifier_layers': True,
 'containLabel': False,
 'dimension': 128,
 'drop_run': False,
 'epochs': 5,
 'finetuning': False,
 'finetuning_epochs': 5,
 'finetuning_learning_rate': 6e-07,
 'finetuning_lr_factor': 0.1,
 'fusion': 'MIL',
 'gpsPosition': 'Hand',
 'haversine_distance': True,
 'highpass_filter': False,
 'input_dropout': 0.3,
 'interp_std_factor': 0.3,
 'interpolation': 'quadratic',
 'intersect': True,
 'learning_rate': 0.0001,
 'locBagPivot': None,
 'locBagSize': 1,
 'locEpochs': 200,
 'loc_features': ['TotalWalk', 'Mean', 'Var'],
 'loc_fusion': 'LSTM',
 'loc_signals': ['Velocity', 'Acceleration'],
 'location_interp_aug': False,
 'location_noise': True,
 'loss_function': 'crossentropy',
 'mask': -10000000,
 'noise_std_factor': 0.5,
 'nullLoc': 'masking',
 'padding_method': 'masking',
 'padding_threshold': 12,
 'pair_threshold': 300000,
 'positions': ['Torso', 'Hips', 'Bag', 'Hand'],
 'post_processing': True,
 'post_processing_method': 'HMM',
 'random_tree': False,
 'second_order': True,
 'seperate_MIL': False,
 'simCLR': 'none',
 'simCLR_criterion': 'augmentation',
 'simCLR_finetuning': True,
 'simCLRepochs': 120,
 'specto_aug': ['frequencyMask', 'timeMask'],
 'spectograms': True,
 'stratify': 'concentrated',
 'testBatchSize': 32,
 'test_user': 1,
 'trainBatchSize': 32,
 'transfer_learning_acc': 'train',
 'transfer_learning_loc': 'none',
 'transition_threshold': 200000,
 'use_gated': True,
 'valBatchSize': 32,
 'val_percentage': 0.3,
 'val_size': 2000}

3 1 1
Found Data
Model: "AccelerationEncoder"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         [(None, 192, 48, 1)]      0         
_________________________________________________________________
accBatch1 (BatchNormalizatio (None, 192, 48, 1)        4         
_________________________________________________________________
zero_padding2d (ZeroPadding2 (None, 194, 50, 1)        0         
_________________________________________________________________
accConv1 (Conv2D)            (None, 192, 48, 16)       160       
_________________________________________________________________
accBatch2 (BatchNormalizatio (None, 192, 48, 16)       64        
_________________________________________________________________
re_lu (ReLU)                 (None, 192, 48, 16)       0         
_________________________________________________________________
max_pooling2d (MaxPooling2D) (None, 96, 24, 16)        0         
_________________________________________________________________
zero_padding2d_1 (ZeroPaddin (None, 98, 26, 16)        0         
_________________________________________________________________
accConv2 (Conv2D)            (None, 96, 24, 32)        4640      
_________________________________________________________________
accBatch3 (BatchNormalizatio (None, 96, 24, 32)        128       
_________________________________________________________________
re_lu_1 (ReLU)               (None, 96, 24, 32)        0         
_________________________________________________________________
max_pooling2d_1 (MaxPooling2 (None, 48, 12, 32)        0         
_________________________________________________________________
accConv3 (Conv2D)            (None, 46, 10, 64)        18496     
_________________________________________________________________
accBatch4 (BatchNormalizatio (None, 46, 10, 64)        256       
_________________________________________________________________
re_lu_2 (ReLU)               (None, 46, 10, 64)        0         
_________________________________________________________________
max_pooling2d_2 (MaxPooling2 (None, 23, 5, 64)         0         
_________________________________________________________________
flatten (Flatten)            (None, 7360)              0         
_________________________________________________________________
dropout (Dropout)            (None, 7360)              0         
_________________________________________________________________
accDense1 (Dense)            (None, 128)               942208    
_________________________________________________________________
accBatch5 (BatchNormalizatio (None, 128)               512       
_________________________________________________________________
re_lu_3 (ReLU)               (None, 128)               0         
_________________________________________________________________
dropout_1 (Dropout)          (None, 128)               0         
_________________________________________________________________
accDense2 (Dense)            (None, 256)               33024     
_________________________________________________________________
accBatch6 (BatchNormalizatio (None, 256)               1024      
_________________________________________________________________
re_lu_4 (ReLU)               (None, 256)               0         
_________________________________________________________________
dropout_2 (Dropout)          (None, 256)               0         
_________________________________________________________________
dense (Dense)                (None, 8)                 2056      
=================================================================
Total params: 1,002,572
Trainable params: 1,001,578
Non-trainable params: 994
_________________________________________________________________
None
Epoch 1/5
  1/153 [..............................] - ETA: 1:19:32 - loss: 2.5709 - categorical_accuracy: 0.1250  2/153 [..............................] - ETA: 2:00 - loss: 2.5530 - categorical_accuracy: 0.1094     3/153 [..............................] - ETA: 2:03 - loss: 2.5004 - categorical_accuracy: 0.1250  4/153 [..............................] - ETA: 2:03 - loss: 2.4397 - categorical_accuracy: 0.1250  5/153 [..............................] - ETA: 2:04 - loss: 2.4684 - categorical_accuracy: 0.1125  6/153 [>.............................] - ETA: 2:03 - loss: 2.4978 - categorical_accuracy: 0.1146  7/153 [>.............................] - ETA: 2:02 - loss: 2.4759 - categorical_accuracy: 0.1295  8/153 [>.............................] - ETA: 2:01 - loss: 2.4906 - categorical_accuracy: 0.1250  9/153 [>.............................] - ETA: 2:00 - loss: 2.4903 - categorical_accuracy: 0.1285 10/153 [>.............................] - ETA: 2:00 - loss: 2.4792 - categorical_accuracy: 0.1344 11/153 [=>............................] - ETA: 1:59 - loss: 2.4724 - categorical_accuracy: 0.1335 12/153 [=>............................] - ETA: 1:58 - loss: 2.4432 - categorical_accuracy: 0.1380 13/153 [=>............................] - ETA: 1:57 - loss: 2.4508 - categorical_accuracy: 0.1418 14/153 [=>............................] - ETA: 1:56 - loss: 2.4310 - categorical_accuracy: 0.1451 15/153 [=>............................] - ETA: 1:56 - loss: 2.4182 - categorical_accuracy: 0.1417 16/153 [==>...........................] - ETA: 1:55 - loss: 2.4002 - categorical_accuracy: 0.1484 17/153 [==>...........................] - ETA: 1:54 - loss: 2.4076 - categorical_accuracy: 0.1471 18/153 [==>...........................] - ETA: 1:53 - loss: 2.3839 - categorical_accuracy: 0.1545 19/153 [==>...........................] - ETA: 1:52 - loss: 2.3702 - categorical_accuracy: 0.1595 20/153 [==>...........................] - ETA: 1:51 - loss: 2.3730 - categorical_accuracy: 0.1547 21/153 [===>..........................] - ETA: 1:50 - loss: 2.3639 - categorical_accuracy: 0.1577 22/153 [===>..........................] - ETA: 1:50 - loss: 2.3546 - categorical_accuracy: 0.1577 23/153 [===>..........................] - ETA: 1:49 - loss: 2.3370 - categorical_accuracy: 0.1630 24/153 [===>..........................] - ETA: 1:48 - loss: 2.3379 - categorical_accuracy: 0.1628 25/153 [===>..........................] - ETA: 1:47 - loss: 2.3345 - categorical_accuracy: 0.1612 26/153 [====>.........................] - ETA: 1:46 - loss: 2.3245 - categorical_accuracy: 0.1647 27/153 [====>.........................] - ETA: 1:46 - loss: 2.3145 - categorical_accuracy: 0.1667 28/153 [====>.........................] - ETA: 1:45 - loss: 2.3059 - categorical_accuracy: 0.1685 29/153 [====>.........................] - ETA: 1:45 - loss: 2.3047 - categorical_accuracy: 0.1670 30/153 [====>.........................] - ETA: 1:45 - loss: 2.2942 - categorical_accuracy: 0.1677 31/153 [=====>........................] - ETA: 1:45 - loss: 2.2912 - categorical_accuracy: 0.1673 32/153 [=====>........................] - ETA: 1:44 - loss: 2.2939 - categorical_accuracy: 0.1650 33/153 [=====>........................] - ETA: 1:44 - loss: 2.2806 - categorical_accuracy: 0.1714 34/153 [=====>........................] - ETA: 1:44 - loss: 2.2686 - categorical_accuracy: 0.1774 35/153 [=====>........................] - ETA: 1:43 - loss: 2.2669 - categorical_accuracy: 0.1786 36/153 [======>.......................] - ETA: 1:43 - loss: 2.2642 - categorical_accuracy: 0.1797 37/153 [======>.......................] - ETA: 1:42 - loss: 2.2670 - categorical_accuracy: 0.1799 38/153 [======>.......................] - ETA: 1:41 - loss: 2.2596 - categorical_accuracy: 0.1834 39/153 [======>.......................] - ETA: 1:41 - loss: 2.2463 - categorical_accuracy: 0.1859 40/153 [======>.......................] - ETA: 1:40 - loss: 2.2425 - categorical_accuracy: 0.1891 41/153 [=======>......................] - ETA: 1:39 - loss: 2.2381 - categorical_accuracy: 0.1905 42/153 [=======>......................] - ETA: 1:39 - loss: 2.2328 - categorical_accuracy: 0.1920 43/153 [=======>......................] - ETA: 1:38 - loss: 2.2224 - categorical_accuracy: 0.1940 44/153 [=======>......................] - ETA: 1:37 - loss: 2.2181 - categorical_accuracy: 0.1953 45/153 [=======>......................] - ETA: 1:36 - loss: 2.2087 - categorical_accuracy: 0.1979 46/153 [========>.....................] - ETA: 1:36 - loss: 2.1998 - categorical_accuracy: 0.1990 47/153 [========>.....................] - ETA: 1:35 - loss: 2.1892 - categorical_accuracy: 0.2048 48/153 [========>.....................] - ETA: 1:34 - loss: 2.1770 - categorical_accuracy: 0.2077 49/153 [========>.....................] - ETA: 1:33 - loss: 2.1689 - categorical_accuracy: 0.2092 50/153 [========>.....................] - ETA: 1:32 - loss: 2.1666 - categorical_accuracy: 0.2125 51/153 [=========>....................] - ETA: 1:31 - loss: 2.1604 - categorical_accuracy: 0.2157 52/153 [=========>....................] - ETA: 1:30 - loss: 2.1596 - categorical_accuracy: 0.2169 53/153 [=========>....................] - ETA: 1:30 - loss: 2.1546 - categorical_accuracy: 0.2193 54/153 [=========>....................] - ETA: 1:29 - loss: 2.1467 - categorical_accuracy: 0.2222 55/153 [=========>....................] - ETA: 1:28 - loss: 2.1447 - categorical_accuracy: 0.2233 56/153 [=========>....................] - ETA: 1:27 - loss: 2.1362 - categorical_accuracy: 0.2249 57/153 [==========>...................] - ETA: 1:26 - loss: 2.1286 - categorical_accuracy: 0.2270 58/153 [==========>...................] - ETA: 1:26 - loss: 2.1213 - categorical_accuracy: 0.2290 59/153 [==========>...................] - ETA: 1:25 - loss: 2.1208 - categorical_accuracy: 0.2283 60/153 [==========>...................] - ETA: 1:24 - loss: 2.1184 - categorical_accuracy: 0.2307 61/153 [==========>...................] - ETA: 1:23 - loss: 2.1166 - categorical_accuracy: 0.2310 62/153 [===========>..................] - ETA: 1:22 - loss: 2.1129 - categorical_accuracy: 0.2344 63/153 [===========>..................] - ETA: 1:22 - loss: 2.1091 - categorical_accuracy: 0.2356 64/153 [===========>..................] - ETA: 1:21 - loss: 2.1068 - categorical_accuracy: 0.2354 65/153 [===========>..................] - ETA: 1:20 - loss: 2.0993 - categorical_accuracy: 0.2394 66/153 [===========>..................] - ETA: 1:19 - loss: 2.0971 - categorical_accuracy: 0.2401 67/153 [============>.................] - ETA: 1:18 - loss: 2.0884 - categorical_accuracy: 0.2444 68/153 [============>.................] - ETA: 1:17 - loss: 2.0865 - categorical_accuracy: 0.2454 69/153 [============>.................] - ETA: 1:16 - loss: 2.0827 - categorical_accuracy: 0.2464 70/153 [============>.................] - ETA: 1:15 - loss: 2.0743 - categorical_accuracy: 0.2500 71/153 [============>.................] - ETA: 1:14 - loss: 2.0762 - categorical_accuracy: 0.2500 72/153 [=============>................] - ETA: 1:14 - loss: 2.0740 - categorical_accuracy: 0.2513 73/153 [=============>................] - ETA: 1:13 - loss: 2.0650 - categorical_accuracy: 0.2551 74/153 [=============>................] - ETA: 1:12 - loss: 2.0604 - categorical_accuracy: 0.2555 75/153 [=============>................] - ETA: 1:11 - loss: 2.0627 - categorical_accuracy: 0.2537 76/153 [=============>................] - ETA: 1:10 - loss: 2.0617 - categorical_accuracy: 0.2549 77/153 [==============>...............] - ETA: 1:09 - loss: 2.0595 - categorical_accuracy: 0.2561 78/153 [==============>...............] - ETA: 1:08 - loss: 2.0530 - categorical_accuracy: 0.2580 79/153 [==============>...............] - ETA: 1:07 - loss: 2.0477 - categorical_accuracy: 0.2595 80/153 [==============>...............] - ETA: 1:07 - loss: 2.0429 - categorical_accuracy: 0.2621 81/153 [==============>...............] - ETA: 1:06 - loss: 2.0378 - categorical_accuracy: 0.2643 82/153 [===============>..............] - ETA: 1:05 - loss: 2.0362 - categorical_accuracy: 0.2668 83/153 [===============>..............] - ETA: 1:04 - loss: 2.0350 - categorical_accuracy: 0.2677 84/153 [===============>..............] - ETA: 1:03 - loss: 2.0338 - categorical_accuracy: 0.2667 85/153 [===============>..............] - ETA: 1:02 - loss: 2.0297 - categorical_accuracy: 0.2684 86/153 [===============>..............] - ETA: 1:01 - loss: 2.0259 - categorical_accuracy: 0.2689 87/153 [================>.............] - ETA: 1:00 - loss: 2.0189 - categorical_accuracy: 0.2719 88/153 [================>.............] - ETA: 59s - loss: 2.0172 - categorical_accuracy: 0.2720  89/153 [================>.............] - ETA: 58s - loss: 2.0117 - categorical_accuracy: 0.2746 90/153 [================>.............] - ETA: 58s - loss: 2.0063 - categorical_accuracy: 0.2764 91/153 [================>.............] - ETA: 57s - loss: 2.0049 - categorical_accuracy: 0.2775 92/153 [=================>............] - ETA: 56s - loss: 2.0024 - categorical_accuracy: 0.2782 93/153 [=================>............] - ETA: 55s - loss: 2.0023 - categorical_accuracy: 0.2786 94/153 [=================>............] - ETA: 54s - loss: 1.9992 - categorical_accuracy: 0.2799 95/153 [=================>............] - ETA: 53s - loss: 2.0028 - categorical_accuracy: 0.2789 96/153 [=================>............] - ETA: 52s - loss: 1.9996 - categorical_accuracy: 0.2806 97/153 [==================>...........] - ETA: 51s - loss: 1.9934 - categorical_accuracy: 0.2825 98/153 [==================>...........] - ETA: 50s - loss: 1.9885 - categorical_accuracy: 0.2835 99/153 [==================>...........] - ETA: 49s - loss: 1.9879 - categorical_accuracy: 0.2831100/153 [==================>...........] - ETA: 48s - loss: 1.9852 - categorical_accuracy: 0.2834101/153 [==================>...........] - ETA: 48s - loss: 1.9803 - categorical_accuracy: 0.2856102/153 [===================>..........] - ETA: 47s - loss: 1.9776 - categorical_accuracy: 0.2880103/153 [===================>..........] - ETA: 46s - loss: 1.9761 - categorical_accuracy: 0.2888104/153 [===================>..........] - ETA: 45s - loss: 1.9738 - categorical_accuracy: 0.2894105/153 [===================>..........] - ETA: 44s - loss: 1.9735 - categorical_accuracy: 0.2890106/153 [===================>..........] - ETA: 43s - loss: 1.9747 - categorical_accuracy: 0.2889107/153 [===================>..........] - ETA: 42s - loss: 1.9718 - categorical_accuracy: 0.2900108/153 [====================>.........] - ETA: 41s - loss: 1.9718 - categorical_accuracy: 0.2905109/153 [====================>.........] - ETA: 40s - loss: 1.9701 - categorical_accuracy: 0.2913110/153 [====================>.........] - ETA: 39s - loss: 1.9694 - categorical_accuracy: 0.2909111/153 [====================>.........] - ETA: 38s - loss: 1.9706 - categorical_accuracy: 0.2900112/153 [====================>.........] - ETA: 37s - loss: 1.9708 - categorical_accuracy: 0.2896113/153 [=====================>........] - ETA: 37s - loss: 1.9709 - categorical_accuracy: 0.2898114/153 [=====================>........] - ETA: 36s - loss: 1.9695 - categorical_accuracy: 0.2900115/153 [=====================>........] - ETA: 35s - loss: 1.9682 - categorical_accuracy: 0.2908116/153 [=====================>........] - ETA: 34s - loss: 1.9648 - categorical_accuracy: 0.2918117/153 [=====================>........] - ETA: 33s - loss: 1.9597 - categorical_accuracy: 0.2930118/153 [======================>.......] - ETA: 32s - loss: 1.9563 - categorical_accuracy: 0.2942119/153 [======================>.......] - ETA: 31s - loss: 1.9541 - categorical_accuracy: 0.2957120/153 [======================>.......] - ETA: 30s - loss: 1.9509 - categorical_accuracy: 0.2971121/153 [======================>.......] - ETA: 29s - loss: 1.9482 - categorical_accuracy: 0.2983122/153 [======================>.......] - ETA: 28s - loss: 1.9420 - categorical_accuracy: 0.3005123/153 [=======================>......] - ETA: 27s - loss: 1.9416 - categorical_accuracy: 0.3013124/153 [=======================>......] - ETA: 26s - loss: 1.9404 - categorical_accuracy: 0.3022125/153 [=======================>......] - ETA: 25s - loss: 1.9412 - categorical_accuracy: 0.3013127/153 [=======================>......] - ETA: 23s - loss: 1.9390 - categorical_accuracy: 0.3034129/153 [========================>.....] - ETA: 21s - loss: 1.9314 - categorical_accuracy: 0.3062131/153 [========================>.....] - ETA: 19s - loss: 1.9237 - categorical_accuracy: 0.3077133/153 [=========================>....] - ETA: 17s - loss: 1.9197 - categorical_accuracy: 0.3078135/153 [=========================>....] - ETA: 15s - loss: 1.9160 - categorical_accuracy: 0.3083137/153 [=========================>....] - ETA: 13s - loss: 1.9096 - categorical_accuracy: 0.3100139/153 [==========================>...] - ETA: 11s - loss: 1.9059 - categorical_accuracy: 0.3103141/153 [==========================>...] - ETA: 9s - loss: 1.8987 - categorical_accuracy: 0.3123 143/153 [===========================>..] - ETA: 7s - loss: 1.8889 - categorical_accuracy: 0.3158145/153 [===========================>..] - ETA: 6s - loss: 1.8849 - categorical_accuracy: 0.3170148/153 [============================>.] - ETA: 3s - loss: 1.8822 - categorical_accuracy: 0.3184151/153 [============================>.] - ETA: 1s - loss: 1.8740 - categorical_accuracy: 0.3216153/153 [==============================] - 191s 1s/step - loss: 1.8679 - categorical_accuracy: 0.3225 - val_loss: 1.3734 - val_categorical_accuracy: 0.5070
 - val_f1: 0.367517 - val_precision: 0.380971 - val_recall: 0.411647

Epoch 00001: val_loss improved from inf to 1.37336, saving model to training\saved_models\shl_acceleration_classifier_model.h5
Epoch 2/5
  1/153 [..............................] - ETA: 4s - loss: 1.5055 - categorical_accuracy: 0.5000  3/153 [..............................] - ETA: 4s - loss: 1.7041 - categorical_accuracy: 0.3854  5/153 [..............................] - ETA: 3s - loss: 1.6717 - categorical_accuracy: 0.3750  7/153 [>.............................] - ETA: 3s - loss: 1.6017 - categorical_accuracy: 0.4018 10/153 [>.............................] - ETA: 3s - loss: 1.6082 - categorical_accuracy: 0.3875 13/153 [=>............................] - ETA: 3s - loss: 1.6006 - categorical_accuracy: 0.4062 16/153 [==>...........................] - ETA: 3s - loss: 1.5872 - categorical_accuracy: 0.4062 19/153 [==>...........................] - ETA: 3s - loss: 1.5706 - categorical_accuracy: 0.4145 22/153 [===>..........................] - ETA: 3s - loss: 1.5636 - categorical_accuracy: 0.4190 25/153 [===>..........................] - ETA: 3s - loss: 1.5415 - categorical_accuracy: 0.4300 28/153 [====>.........................] - ETA: 3s - loss: 1.5485 - categorical_accuracy: 0.4219 31/153 [=====>........................] - ETA: 2s - loss: 1.5505 - categorical_accuracy: 0.4194 33/153 [=====>........................] - ETA: 2s - loss: 1.5344 - categorical_accuracy: 0.4252 36/153 [======>.......................] - ETA: 2s - loss: 1.5248 - categorical_accuracy: 0.4323 38/153 [======>.......................] - ETA: 2s - loss: 1.5186 - categorical_accuracy: 0.4367 40/153 [======>.......................] - ETA: 2s - loss: 1.5253 - categorical_accuracy: 0.4383 43/153 [=======>......................] - ETA: 2s - loss: 1.5149 - categorical_accuracy: 0.4382 46/153 [========>.....................] - ETA: 2s - loss: 1.5075 - categorical_accuracy: 0.4402 48/153 [========>.....................] - ETA: 2s - loss: 1.5122 - categorical_accuracy: 0.4382 50/153 [========>.....................] - ETA: 2s - loss: 1.5030 - categorical_accuracy: 0.4437 53/153 [=========>....................] - ETA: 2s - loss: 1.4936 - categorical_accuracy: 0.4499 56/153 [=========>....................] - ETA: 2s - loss: 1.4986 - categorical_accuracy: 0.4520 58/153 [==========>...................] - ETA: 2s - loss: 1.4939 - categorical_accuracy: 0.4558 61/153 [==========>...................] - ETA: 2s - loss: 1.5069 - categorical_accuracy: 0.4518 64/153 [===========>..................] - ETA: 2s - loss: 1.5103 - categorical_accuracy: 0.4526 67/153 [============>.................] - ETA: 2s - loss: 1.4973 - categorical_accuracy: 0.4580 70/153 [============>.................] - ETA: 2s - loss: 1.5008 - categorical_accuracy: 0.4576 73/153 [=============>................] - ETA: 1s - loss: 1.5056 - categorical_accuracy: 0.4572 76/153 [=============>................] - ETA: 1s - loss: 1.5029 - categorical_accuracy: 0.4576 79/153 [==============>...............] - ETA: 1s - loss: 1.5031 - categorical_accuracy: 0.4577 82/153 [===============>..............] - ETA: 1s - loss: 1.4910 - categorical_accuracy: 0.4619 85/153 [===============>..............] - ETA: 1s - loss: 1.4942 - categorical_accuracy: 0.4629 88/153 [================>.............] - ETA: 1s - loss: 1.4895 - categorical_accuracy: 0.4656 91/153 [================>.............] - ETA: 1s - loss: 1.4853 - categorical_accuracy: 0.4663 94/153 [=================>............] - ETA: 1s - loss: 1.4814 - categorical_accuracy: 0.4671 96/153 [=================>............] - ETA: 1s - loss: 1.4812 - categorical_accuracy: 0.4668 99/153 [==================>...........] - ETA: 1s - loss: 1.4815 - categorical_accuracy: 0.4672102/153 [===================>..........] - ETA: 1s - loss: 1.4748 - categorical_accuracy: 0.4681105/153 [===================>..........] - ETA: 1s - loss: 1.4726 - categorical_accuracy: 0.4690108/153 [====================>.........] - ETA: 1s - loss: 1.4715 - categorical_accuracy: 0.4693111/153 [====================>.........] - ETA: 1s - loss: 1.4686 - categorical_accuracy: 0.4690114/153 [=====================>........] - ETA: 0s - loss: 1.4679 - categorical_accuracy: 0.4696117/153 [=====================>........] - ETA: 0s - loss: 1.4657 - categorical_accuracy: 0.4698120/153 [======================>.......] - ETA: 0s - loss: 1.4602 - categorical_accuracy: 0.4716123/153 [=======================>......] - ETA: 0s - loss: 1.4539 - categorical_accuracy: 0.4733126/153 [=======================>......] - ETA: 0s - loss: 1.4481 - categorical_accuracy: 0.4754128/153 [========================>.....] - ETA: 0s - loss: 1.4477 - categorical_accuracy: 0.4775131/153 [========================>.....] - ETA: 0s - loss: 1.4415 - categorical_accuracy: 0.4781133/153 [=========================>....] - ETA: 0s - loss: 1.4408 - categorical_accuracy: 0.4779135/153 [=========================>....] - ETA: 0s - loss: 1.4417 - categorical_accuracy: 0.4773137/153 [=========================>....] - ETA: 0s - loss: 1.4426 - categorical_accuracy: 0.4772139/153 [==========================>...] - ETA: 0s - loss: 1.4420 - categorical_accuracy: 0.4775141/153 [==========================>...] - ETA: 0s - loss: 1.4380 - categorical_accuracy: 0.4789144/153 [===========================>..] - ETA: 0s - loss: 1.4358 - categorical_accuracy: 0.4803147/153 [===========================>..] - ETA: 0s - loss: 1.4366 - categorical_accuracy: 0.4809150/153 [============================>.] - ETA: 0s - loss: 1.4383 - categorical_accuracy: 0.4810153/153 [==============================] - ETA: 0s - loss: 1.4355 - categorical_accuracy: 0.4820153/153 [==============================] - 5s 33ms/step - loss: 1.4355 - categorical_accuracy: 0.4820 - val_loss: 1.3019 - val_categorical_accuracy: 0.5514
 - val_f1: 0.413452 - val_precision: 0.424045 - val_recall: 0.450791

Epoch 00002: val_loss improved from 1.37336 to 1.30189, saving model to training\saved_models\shl_acceleration_classifier_model.h5
Epoch 3/5
  1/153 [..............................] - ETA: 3s - loss: 1.3546 - categorical_accuracy: 0.5938  4/153 [..............................] - ETA: 3s - loss: 1.1534 - categorical_accuracy: 0.5703  6/153 [>.............................] - ETA: 3s - loss: 1.2116 - categorical_accuracy: 0.5260  8/153 [>.............................] - ETA: 3s - loss: 1.2416 - categorical_accuracy: 0.5000 10/153 [>.............................] - ETA: 3s - loss: 1.2485 - categorical_accuracy: 0.4969 12/153 [=>............................] - ETA: 3s - loss: 1.2473 - categorical_accuracy: 0.5052 15/153 [=>............................] - ETA: 3s - loss: 1.2536 - categorical_accuracy: 0.5146 18/153 [==>...........................] - ETA: 3s - loss: 1.2860 - categorical_accuracy: 0.5104 21/153 [===>..........................] - ETA: 3s - loss: 1.3025 - categorical_accuracy: 0.5030 23/153 [===>..........................] - ETA: 3s - loss: 1.2915 - categorical_accuracy: 0.5122 26/153 [====>.........................] - ETA: 3s - loss: 1.2806 - categorical_accuracy: 0.5192 29/153 [====>.........................] - ETA: 3s - loss: 1.2753 - categorical_accuracy: 0.5216 32/153 [=====>........................] - ETA: 2s - loss: 1.2690 - categorical_accuracy: 0.5225 35/153 [=====>........................] - ETA: 2s - loss: 1.2633 - categorical_accuracy: 0.5241 37/153 [======>.......................] - ETA: 2s - loss: 1.2691 - categorical_accuracy: 0.5245 39/153 [======>.......................] - ETA: 2s - loss: 1.2903 - categorical_accuracy: 0.5192 42/153 [=======>......................] - ETA: 2s - loss: 1.2927 - categorical_accuracy: 0.5268 45/153 [=======>......................] - ETA: 2s - loss: 1.2849 - categorical_accuracy: 0.5312 48/153 [========>.....................] - ETA: 2s - loss: 1.2799 - categorical_accuracy: 0.5358 50/153 [========>.....................] - ETA: 2s - loss: 1.2707 - categorical_accuracy: 0.5419 53/153 [=========>....................] - ETA: 2s - loss: 1.2602 - categorical_accuracy: 0.5425 56/153 [=========>....................] - ETA: 2s - loss: 1.2639 - categorical_accuracy: 0.5407 59/153 [==========>...................] - ETA: 2s - loss: 1.2630 - categorical_accuracy: 0.5413 61/153 [==========>...................] - ETA: 2s - loss: 1.2569 - categorical_accuracy: 0.5430 64/153 [===========>..................] - ETA: 2s - loss: 1.2544 - categorical_accuracy: 0.5435 67/153 [============>.................] - ETA: 2s - loss: 1.2478 - categorical_accuracy: 0.5466 70/153 [============>.................] - ETA: 2s - loss: 1.2494 - categorical_accuracy: 0.5455 73/153 [=============>................] - ETA: 1s - loss: 1.2524 - categorical_accuracy: 0.5441 75/153 [=============>................] - ETA: 1s - loss: 1.2476 - categorical_accuracy: 0.5458 78/153 [==============>...............] - ETA: 1s - loss: 1.2418 - categorical_accuracy: 0.5469 81/153 [==============>...............] - ETA: 1s - loss: 1.2447 - categorical_accuracy: 0.5459 84/153 [===============>..............] - ETA: 1s - loss: 1.2528 - categorical_accuracy: 0.5454 87/153 [================>.............] - ETA: 1s - loss: 1.2496 - categorical_accuracy: 0.5467 90/153 [================>.............] - ETA: 1s - loss: 1.2505 - categorical_accuracy: 0.5462 93/153 [=================>............] - ETA: 1s - loss: 1.2557 - categorical_accuracy: 0.5444 95/153 [=================>............] - ETA: 1s - loss: 1.2508 - categorical_accuracy: 0.5467 97/153 [==================>...........] - ETA: 1s - loss: 1.2526 - categorical_accuracy: 0.5470 99/153 [==================>...........] - ETA: 1s - loss: 1.2496 - categorical_accuracy: 0.5492101/153 [==================>...........] - ETA: 1s - loss: 1.2476 - categorical_accuracy: 0.5486103/153 [===================>..........] - ETA: 1s - loss: 1.2480 - categorical_accuracy: 0.5485105/153 [===================>..........] - ETA: 1s - loss: 1.2458 - categorical_accuracy: 0.5488108/153 [====================>.........] - ETA: 1s - loss: 1.2472 - categorical_accuracy: 0.5466110/153 [====================>.........] - ETA: 1s - loss: 1.2535 - categorical_accuracy: 0.5466112/153 [====================>.........] - ETA: 1s - loss: 1.2605 - categorical_accuracy: 0.5455114/153 [=====================>........] - ETA: 0s - loss: 1.2593 - categorical_accuracy: 0.5469116/153 [=====================>........] - ETA: 0s - loss: 1.2529 - categorical_accuracy: 0.5488118/153 [======================>.......] - ETA: 0s - loss: 1.2536 - categorical_accuracy: 0.5482120/153 [======================>.......] - ETA: 0s - loss: 1.2551 - categorical_accuracy: 0.5484122/153 [======================>.......] - ETA: 0s - loss: 1.2561 - categorical_accuracy: 0.5479125/153 [=======================>......] - ETA: 0s - loss: 1.2586 - categorical_accuracy: 0.5472128/153 [========================>.....] - ETA: 0s - loss: 1.2607 - categorical_accuracy: 0.5471131/153 [========================>.....] - ETA: 0s - loss: 1.2626 - categorical_accuracy: 0.5456133/153 [=========================>....] - ETA: 0s - loss: 1.2622 - categorical_accuracy: 0.5442135/153 [=========================>....] - ETA: 0s - loss: 1.2622 - categorical_accuracy: 0.5442138/153 [==========================>...] - ETA: 0s - loss: 1.2626 - categorical_accuracy: 0.5437140/153 [==========================>...] - ETA: 0s - loss: 1.2604 - categorical_accuracy: 0.5446142/153 [==========================>...] - ETA: 0s - loss: 1.2585 - categorical_accuracy: 0.5460144/153 [===========================>..] - ETA: 0s - loss: 1.2570 - categorical_accuracy: 0.5473147/153 [===========================>..] - ETA: 0s - loss: 1.2549 - categorical_accuracy: 0.5480150/153 [============================>.] - ETA: 0s - loss: 1.2506 - categorical_accuracy: 0.5494153/153 [==============================] - ETA: 0s - loss: 1.2506 - categorical_accuracy: 0.5492153/153 [==============================] - 5s 33ms/step - loss: 1.2506 - categorical_accuracy: 0.5492 - val_loss: 1.2151 - val_categorical_accuracy: 0.5721
 - val_f1: 0.437427 - val_precision: 0.441235 - val_recall: 0.474210

Epoch 00003: val_loss improved from 1.30189 to 1.21509, saving model to training\saved_models\shl_acceleration_classifier_model.h5
Epoch 4/5
  1/153 [..............................] - ETA: 3s - loss: 1.5442 - categorical_accuracy: 0.5000  4/153 [..............................] - ETA: 3s - loss: 1.3043 - categorical_accuracy: 0.5234  7/153 [>.............................] - ETA: 3s - loss: 1.2135 - categorical_accuracy: 0.5759 10/153 [>.............................] - ETA: 3s - loss: 1.1739 - categorical_accuracy: 0.5938 13/153 [=>............................] - ETA: 3s - loss: 1.1673 - categorical_accuracy: 0.5889 16/153 [==>...........................] - ETA: 3s - loss: 1.1371 - categorical_accuracy: 0.5957 19/153 [==>...........................] - ETA: 3s - loss: 1.1502 - categorical_accuracy: 0.5806 21/153 [===>..........................] - ETA: 3s - loss: 1.1387 - categorical_accuracy: 0.5848 24/153 [===>..........................] - ETA: 3s - loss: 1.1496 - categorical_accuracy: 0.5781 26/153 [====>.........................] - ETA: 3s - loss: 1.1550 - categorical_accuracy: 0.5829 29/153 [====>.........................] - ETA: 2s - loss: 1.1375 - categorical_accuracy: 0.5894 32/153 [=====>........................] - ETA: 2s - loss: 1.1601 - categorical_accuracy: 0.5771 35/153 [=====>........................] - ETA: 2s - loss: 1.1588 - categorical_accuracy: 0.5848 38/153 [======>.......................] - ETA: 2s - loss: 1.1700 - categorical_accuracy: 0.5757 41/153 [=======>......................] - ETA: 2s - loss: 1.1719 - categorical_accuracy: 0.5777 43/153 [=======>......................] - ETA: 2s - loss: 1.1734 - categorical_accuracy: 0.5792 45/153 [=======>......................] - ETA: 2s - loss: 1.1714 - categorical_accuracy: 0.5792 48/153 [========>.....................] - ETA: 2s - loss: 1.1746 - categorical_accuracy: 0.5788 50/153 [========>.....................] - ETA: 2s - loss: 1.1786 - categorical_accuracy: 0.5781 53/153 [=========>....................] - ETA: 2s - loss: 1.1719 - categorical_accuracy: 0.5808 56/153 [=========>....................] - ETA: 2s - loss: 1.1700 - categorical_accuracy: 0.5859 58/153 [==========>...................] - ETA: 2s - loss: 1.1726 - categorical_accuracy: 0.5862 60/153 [==========>...................] - ETA: 2s - loss: 1.1822 - categorical_accuracy: 0.5844 62/153 [===========>..................] - ETA: 2s - loss: 1.1792 - categorical_accuracy: 0.5847 65/153 [===========>..................] - ETA: 2s - loss: 1.1790 - categorical_accuracy: 0.5875 68/153 [============>.................] - ETA: 2s - loss: 1.1803 - categorical_accuracy: 0.5827 71/153 [============>.................] - ETA: 2s - loss: 1.1789 - categorical_accuracy: 0.5832 74/153 [=============>................] - ETA: 1s - loss: 1.1782 - categorical_accuracy: 0.5823 77/153 [==============>...............] - ETA: 1s - loss: 1.1849 - categorical_accuracy: 0.5804 79/153 [==============>...............] - ETA: 1s - loss: 1.1780 - categorical_accuracy: 0.5823 81/153 [==============>...............] - ETA: 1s - loss: 1.1746 - categorical_accuracy: 0.5841 84/153 [===============>..............] - ETA: 1s - loss: 1.1728 - categorical_accuracy: 0.5844 87/153 [================>.............] - ETA: 1s - loss: 1.1735 - categorical_accuracy: 0.5858 90/153 [================>.............] - ETA: 1s - loss: 1.1743 - categorical_accuracy: 0.5858 93/153 [=================>............] - ETA: 1s - loss: 1.1739 - categorical_accuracy: 0.5860 96/153 [=================>............] - ETA: 1s - loss: 1.1724 - categorical_accuracy: 0.5866 99/153 [==================>...........] - ETA: 1s - loss: 1.1685 - categorical_accuracy: 0.5893102/153 [===================>..........] - ETA: 1s - loss: 1.1650 - categorical_accuracy: 0.5913105/153 [===================>..........] - ETA: 1s - loss: 1.1605 - categorical_accuracy: 0.5920108/153 [====================>.........] - ETA: 1s - loss: 1.1518 - categorical_accuracy: 0.5952111/153 [====================>.........] - ETA: 1s - loss: 1.1493 - categorical_accuracy: 0.5954114/153 [=====================>........] - ETA: 0s - loss: 1.1546 - categorical_accuracy: 0.5935116/153 [=====================>........] - ETA: 0s - loss: 1.1521 - categorical_accuracy: 0.5935118/153 [======================>.......] - ETA: 0s - loss: 1.1532 - categorical_accuracy: 0.5916120/153 [======================>.......] - ETA: 0s - loss: 1.1525 - categorical_accuracy: 0.5922122/153 [======================>.......] - ETA: 0s - loss: 1.1542 - categorical_accuracy: 0.5927124/153 [=======================>......] - ETA: 0s - loss: 1.1534 - categorical_accuracy: 0.5938127/153 [=======================>......] - ETA: 0s - loss: 1.1561 - categorical_accuracy: 0.5928130/153 [========================>.....] - ETA: 0s - loss: 1.1546 - categorical_accuracy: 0.5928133/153 [=========================>....] - ETA: 0s - loss: 1.1510 - categorical_accuracy: 0.5942136/153 [=========================>....] - ETA: 0s - loss: 1.1490 - categorical_accuracy: 0.5940139/153 [==========================>...] - ETA: 0s - loss: 1.1481 - categorical_accuracy: 0.5935142/153 [==========================>...] - ETA: 0s - loss: 1.1479 - categorical_accuracy: 0.5951145/153 [===========================>..] - ETA: 0s - loss: 1.1479 - categorical_accuracy: 0.5946148/153 [============================>.] - ETA: 0s - loss: 1.1476 - categorical_accuracy: 0.5944151/153 [============================>.] - ETA: 0s - loss: 1.1483 - categorical_accuracy: 0.5942153/153 [==============================] - 5s 33ms/step - loss: 1.1459 - categorical_accuracy: 0.5954 - val_loss: 1.1317 - val_categorical_accuracy: 0.6018
 - val_f1: 0.456868 - val_precision: 0.436147 - val_recall: 0.502648

Epoch 00004: val_loss improved from 1.21509 to 1.13165, saving model to training\saved_models\shl_acceleration_classifier_model.h5
Epoch 5/5
  1/153 [..............................] - ETA: 4s - loss: 1.0777 - categorical_accuracy: 0.5000  3/153 [..............................] - ETA: 3s - loss: 1.1204 - categorical_accuracy: 0.5625  5/153 [..............................] - ETA: 3s - loss: 1.0628 - categorical_accuracy: 0.5750  7/153 [>.............................] - ETA: 3s - loss: 1.0437 - categorical_accuracy: 0.5982  9/153 [>.............................] - ETA: 3s - loss: 1.0661 - categorical_accuracy: 0.5972 11/153 [=>............................] - ETA: 3s - loss: 1.0607 - categorical_accuracy: 0.5966 13/153 [=>............................] - ETA: 3s - loss: 1.0867 - categorical_accuracy: 0.5841 15/153 [=>............................] - ETA: 3s - loss: 1.1039 - categorical_accuracy: 0.5792 18/153 [==>...........................] - ETA: 3s - loss: 1.0947 - categorical_accuracy: 0.5868 21/153 [===>..........................] - ETA: 3s - loss: 1.0762 - categorical_accuracy: 0.5997 24/153 [===>..........................] - ETA: 3s - loss: 1.0935 - categorical_accuracy: 0.5938 27/153 [====>.........................] - ETA: 3s - loss: 1.0842 - categorical_accuracy: 0.5972 30/153 [====>.........................] - ETA: 3s - loss: 1.0897 - categorical_accuracy: 0.5927 33/153 [=====>........................] - ETA: 2s - loss: 1.0887 - categorical_accuracy: 0.5985 36/153 [======>.......................] - ETA: 2s - loss: 1.0760 - categorical_accuracy: 0.6050 39/153 [======>.......................] - ETA: 2s - loss: 1.0871 - categorical_accuracy: 0.6018 42/153 [=======>......................] - ETA: 2s - loss: 1.0739 - categorical_accuracy: 0.6057 45/153 [=======>......................] - ETA: 2s - loss: 1.0754 - categorical_accuracy: 0.6076 48/153 [========>.....................] - ETA: 2s - loss: 1.0724 - categorical_accuracy: 0.6113 51/153 [=========>....................] - ETA: 2s - loss: 1.0761 - categorical_accuracy: 0.6097 54/153 [=========>....................] - ETA: 2s - loss: 1.0766 - categorical_accuracy: 0.6128 57/153 [==========>...................] - ETA: 2s - loss: 1.0784 - categorical_accuracy: 0.6113 60/153 [==========>...................] - ETA: 2s - loss: 1.0745 - categorical_accuracy: 0.6156 63/153 [===========>..................] - ETA: 2s - loss: 1.0714 - categorical_accuracy: 0.6181 66/153 [===========>..................] - ETA: 2s - loss: 1.0821 - categorical_accuracy: 0.6174 69/153 [============>.................] - ETA: 1s - loss: 1.0822 - categorical_accuracy: 0.6178 72/153 [=============>................] - ETA: 1s - loss: 1.0822 - categorical_accuracy: 0.6189 75/153 [=============>................] - ETA: 1s - loss: 1.0824 - categorical_accuracy: 0.6200 78/153 [==============>...............] - ETA: 1s - loss: 1.0890 - categorical_accuracy: 0.6190 81/153 [==============>...............] - ETA: 1s - loss: 1.0872 - categorical_accuracy: 0.6208 84/153 [===============>..............] - ETA: 1s - loss: 1.0856 - categorical_accuracy: 0.6198 87/153 [================>.............] - ETA: 1s - loss: 1.0804 - categorical_accuracy: 0.6221 90/153 [================>.............] - ETA: 1s - loss: 1.0813 - categorical_accuracy: 0.6212 93/153 [=================>............] - ETA: 1s - loss: 1.0825 - categorical_accuracy: 0.6200 96/153 [=================>............] - ETA: 1s - loss: 1.0777 - categorical_accuracy: 0.6208 99/153 [==================>...........] - ETA: 1s - loss: 1.0753 - categorical_accuracy: 0.6228102/153 [===================>..........] - ETA: 1s - loss: 1.0695 - categorical_accuracy: 0.6247105/153 [===================>..........] - ETA: 1s - loss: 1.0688 - categorical_accuracy: 0.6241108/153 [====================>.........] - ETA: 1s - loss: 1.0662 - categorical_accuracy: 0.6247111/153 [====================>.........] - ETA: 0s - loss: 1.0608 - categorical_accuracy: 0.6273114/153 [=====================>........] - ETA: 0s - loss: 1.0599 - categorical_accuracy: 0.6266117/153 [=====================>........] - ETA: 0s - loss: 1.0592 - categorical_accuracy: 0.6263120/153 [======================>.......] - ETA: 0s - loss: 1.0570 - categorical_accuracy: 0.6281123/153 [=======================>......] - ETA: 0s - loss: 1.0545 - categorical_accuracy: 0.6286126/153 [=======================>......] - ETA: 0s - loss: 1.0536 - categorical_accuracy: 0.6275129/153 [========================>.....] - ETA: 0s - loss: 1.0533 - categorical_accuracy: 0.6277132/153 [========================>.....] - ETA: 0s - loss: 1.0503 - categorical_accuracy: 0.6290135/153 [=========================>....] - ETA: 0s - loss: 1.0524 - categorical_accuracy: 0.6273138/153 [==========================>...] - ETA: 0s - loss: 1.0494 - categorical_accuracy: 0.6286141/153 [==========================>...] - ETA: 0s - loss: 1.0520 - categorical_accuracy: 0.6281144/153 [===========================>..] - ETA: 0s - loss: 1.0544 - categorical_accuracy: 0.6263147/153 [===========================>..] - ETA: 0s - loss: 1.0523 - categorical_accuracy: 0.6280150/153 [============================>.] - ETA: 0s - loss: 1.0500 - categorical_accuracy: 0.6285153/153 [==============================] - ETA: 0s - loss: 1.0513 - categorical_accuracy: 0.6281153/153 [==============================] - 5s 31ms/step - loss: 1.0513 - categorical_accuracy: 0.6281 - val_loss: 1.0832 - val_categorical_accuracy: 0.6276
 - val_f1: 0.477138 - val_precision: 0.454731 - val_recall: 0.529907

Epoch 00005: val_loss improved from 1.13165 to 1.08315, saving model to training\saved_models\shl_acceleration_classifier_model.h5
 - val_f1: 0.477068 - val_precision: 0.454905 - val_recall: 0.529657
  1/125 [..............................] - ETA: 21:15 - loss: 1.0652 - categorical_accuracy: 0.6250  2/125 [..............................] - ETA: 39s - loss: 1.1359 - categorical_accuracy: 0.6250    3/125 [..............................] - ETA: 38s - loss: 1.3228 - categorical_accuracy: 0.5625  4/125 [..............................] - ETA: 38s - loss: 1.3665 - categorical_accuracy: 0.5469  5/125 [>.............................] - ETA: 38s - loss: 1.4059 - categorical_accuracy: 0.5250  6/125 [>.............................] - ETA: 38s - loss: 1.3787 - categorical_accuracy: 0.5365  7/125 [>.............................] - ETA: 37s - loss: 1.4311 - categorical_accuracy: 0.5000  8/125 [>.............................] - ETA: 37s - loss: 1.3734 - categorical_accuracy: 0.5195  9/125 [=>............................] - ETA: 37s - loss: 1.3402 - categorical_accuracy: 0.5278 10/125 [=>............................] - ETA: 36s - loss: 1.3121 - categorical_accuracy: 0.5437 11/125 [=>............................] - ETA: 36s - loss: 1.2877 - categorical_accuracy: 0.5540 12/125 [=>............................] - ETA: 36s - loss: 1.3067 - categorical_accuracy: 0.5417 13/125 [==>...........................] - ETA: 35s - loss: 1.3419 - categorical_accuracy: 0.5288 14/125 [==>...........................] - ETA: 35s - loss: 1.3341 - categorical_accuracy: 0.5290 15/125 [==>...........................] - ETA: 35s - loss: 1.3254 - categorical_accuracy: 0.5375 16/125 [==>...........................] - ETA: 34s - loss: 1.3167 - categorical_accuracy: 0.5410 17/125 [===>..........................] - ETA: 34s - loss: 1.3321 - categorical_accuracy: 0.5368 18/125 [===>..........................] - ETA: 34s - loss: 1.3647 - categorical_accuracy: 0.5278 19/125 [===>..........................] - ETA: 34s - loss: 1.3719 - categorical_accuracy: 0.5247 20/125 [===>..........................] - ETA: 33s - loss: 1.3536 - categorical_accuracy: 0.5281 21/125 [====>.........................] - ETA: 33s - loss: 1.3645 - categorical_accuracy: 0.5283 22/125 [====>.........................] - ETA: 33s - loss: 1.3645 - categorical_accuracy: 0.5256 23/125 [====>.........................] - ETA: 32s - loss: 1.3768 - categorical_accuracy: 0.5217 24/125 [====>.........................] - ETA: 32s - loss: 1.3653 - categorical_accuracy: 0.5221 25/125 [=====>........................] - ETA: 32s - loss: 1.3597 - categorical_accuracy: 0.5238 26/125 [=====>........................] - ETA: 31s - loss: 1.3646 - categorical_accuracy: 0.5228 27/125 [=====>........................] - ETA: 31s - loss: 1.3644 - categorical_accuracy: 0.5231 28/125 [=====>........................] - ETA: 31s - loss: 1.3689 - categorical_accuracy: 0.5246 29/125 [=====>........................] - ETA: 30s - loss: 1.3610 - categorical_accuracy: 0.5269 30/125 [======>.......................] - ETA: 30s - loss: 1.3601 - categorical_accuracy: 0.5281 31/125 [======>.......................] - ETA: 30s - loss: 1.3627 - categorical_accuracy: 0.5272 32/125 [======>.......................] - ETA: 29s - loss: 1.3657 - categorical_accuracy: 0.5205 33/125 [======>.......................] - ETA: 29s - loss: 1.3610 - categorical_accuracy: 0.5218 34/125 [=======>......................] - ETA: 29s - loss: 1.3509 - categorical_accuracy: 0.5248 35/125 [=======>......................] - ETA: 28s - loss: 1.3549 - categorical_accuracy: 0.5214 36/125 [=======>......................] - ETA: 28s - loss: 1.3620 - categorical_accuracy: 0.5191 37/125 [=======>......................] - ETA: 28s - loss: 1.3704 - categorical_accuracy: 0.5160 38/125 [========>.....................] - ETA: 27s - loss: 1.3855 - categorical_accuracy: 0.5115 39/125 [========>.....................] - ETA: 27s - loss: 1.3875 - categorical_accuracy: 0.5136 40/125 [========>.....................] - ETA: 27s - loss: 1.3828 - categorical_accuracy: 0.5156 41/125 [========>.....................] - ETA: 26s - loss: 1.3856 - categorical_accuracy: 0.5130 42/125 [=========>....................] - ETA: 26s - loss: 1.3798 - categorical_accuracy: 0.5119 43/125 [=========>....................] - ETA: 26s - loss: 1.3750 - categorical_accuracy: 0.5138 44/125 [=========>....................] - ETA: 25s - loss: 1.3761 - categorical_accuracy: 0.5121 45/125 [=========>....................] - ETA: 25s - loss: 1.3720 - categorical_accuracy: 0.5132 46/125 [==========>...................] - ETA: 25s - loss: 1.3669 - categorical_accuracy: 0.5163 47/125 [==========>...................] - ETA: 24s - loss: 1.3696 - categorical_accuracy: 0.5160 48/125 [==========>...................] - ETA: 24s - loss: 1.3757 - categorical_accuracy: 0.5143 49/125 [==========>...................] - ETA: 24s - loss: 1.3804 - categorical_accuracy: 0.5147 50/125 [===========>..................] - ETA: 24s - loss: 1.3799 - categorical_accuracy: 0.5138 51/125 [===========>..................] - ETA: 23s - loss: 1.3786 - categorical_accuracy: 0.5153 52/125 [===========>..................] - ETA: 23s - loss: 1.3806 - categorical_accuracy: 0.5144 53/125 [===========>..................] - ETA: 23s - loss: 1.3815 - categorical_accuracy: 0.5130 54/125 [===========>..................] - ETA: 22s - loss: 1.3818 - categorical_accuracy: 0.5133 55/125 [============>.................] - ETA: 22s - loss: 1.3793 - categorical_accuracy: 0.5148 56/125 [============>.................] - ETA: 22s - loss: 1.3825 - categorical_accuracy: 0.5134 57/125 [============>.................] - ETA: 21s - loss: 1.3766 - categorical_accuracy: 0.5164 58/125 [============>.................] - ETA: 21s - loss: 1.3794 - categorical_accuracy: 0.5151 59/125 [=============>................] - ETA: 21s - loss: 1.3765 - categorical_accuracy: 0.5164 60/125 [=============>................] - ETA: 20s - loss: 1.3804 - categorical_accuracy: 0.5156 61/125 [=============>................] - ETA: 20s - loss: 1.3833 - categorical_accuracy: 0.5149 62/125 [=============>................] - ETA: 20s - loss: 1.3858 - categorical_accuracy: 0.5151 63/125 [==============>...............] - ETA: 19s - loss: 1.3876 - categorical_accuracy: 0.5149 64/125 [==============>...............] - ETA: 19s - loss: 1.3900 - categorical_accuracy: 0.5137 65/125 [==============>...............] - ETA: 19s - loss: 1.3935 - categorical_accuracy: 0.5130 66/125 [==============>...............] - ETA: 18s - loss: 1.3934 - categorical_accuracy: 0.5123 67/125 [===============>..............] - ETA: 18s - loss: 1.3945 - categorical_accuracy: 0.5112 68/125 [===============>..............] - ETA: 18s - loss: 1.3936 - categorical_accuracy: 0.5110 69/125 [===============>..............] - ETA: 17s - loss: 1.3940 - categorical_accuracy: 0.5109 70/125 [===============>..............] - ETA: 17s - loss: 1.3891 - categorical_accuracy: 0.5121 71/125 [================>.............] - ETA: 17s - loss: 1.3856 - categorical_accuracy: 0.5123 72/125 [================>.............] - ETA: 17s - loss: 1.3798 - categorical_accuracy: 0.5148 73/125 [================>.............] - ETA: 16s - loss: 1.3827 - categorical_accuracy: 0.5141 74/125 [================>.............] - ETA: 16s - loss: 1.3801 - categorical_accuracy: 0.5165 75/125 [=================>............] - ETA: 16s - loss: 1.3799 - categorical_accuracy: 0.5167 76/125 [=================>............] - ETA: 15s - loss: 1.3803 - categorical_accuracy: 0.5173 77/125 [=================>............] - ETA: 15s - loss: 1.3766 - categorical_accuracy: 0.5170 78/125 [=================>............] - ETA: 15s - loss: 1.3774 - categorical_accuracy: 0.5164 79/125 [=================>............] - ETA: 14s - loss: 1.3756 - categorical_accuracy: 0.5166 80/125 [==================>...........] - ETA: 14s - loss: 1.3754 - categorical_accuracy: 0.5156 81/125 [==================>...........] - ETA: 14s - loss: 1.3760 - categorical_accuracy: 0.5162 82/125 [==================>...........] - ETA: 13s - loss: 1.3744 - categorical_accuracy: 0.5175 83/125 [==================>...........] - ETA: 13s - loss: 1.3750 - categorical_accuracy: 0.5177 84/125 [===================>..........] - ETA: 13s - loss: 1.3747 - categorical_accuracy: 0.5179 85/125 [===================>..........] - ETA: 12s - loss: 1.3750 - categorical_accuracy: 0.5176 86/125 [===================>..........] - ETA: 12s - loss: 1.3774 - categorical_accuracy: 0.5164 87/125 [===================>..........] - ETA: 12s - loss: 1.3815 - categorical_accuracy: 0.5140 88/125 [====================>.........] - ETA: 11s - loss: 1.3811 - categorical_accuracy: 0.5142 89/125 [====================>.........] - ETA: 11s - loss: 1.3837 - categorical_accuracy: 0.5140 90/125 [====================>.........] - ETA: 11s - loss: 1.3838 - categorical_accuracy: 0.5125 91/125 [====================>.........] - ETA: 10s - loss: 1.3810 - categorical_accuracy: 0.5130 92/125 [=====================>........] - ETA: 10s - loss: 1.3799 - categorical_accuracy: 0.5129 93/125 [=====================>........] - ETA: 10s - loss: 1.3759 - categorical_accuracy: 0.5141 94/125 [=====================>........] - ETA: 9s - loss: 1.3739 - categorical_accuracy: 0.5156  96/125 [======================>.......] - ETA: 9s - loss: 1.3709 - categorical_accuracy: 0.5176 98/125 [======================>.......] - ETA: 8s - loss: 1.3739 - categorical_accuracy: 0.5163102/125 [=======================>......] - ETA: 6s - loss: 1.3749 - categorical_accuracy: 0.5159107/125 [========================>.....] - ETA: 5s - loss: 1.3762 - categorical_accuracy: 0.5152113/125 [==========================>...] - ETA: 3s - loss: 1.3823 - categorical_accuracy: 0.5127119/125 [===========================>..] - ETA: 1s - loss: 1.3806 - categorical_accuracy: 0.5102125/125 [==============================] - ETA: 0s - loss: 1.3783 - categorical_accuracy: 0.5113125/125 [==============================] - 41s 244ms/step - loss: 1.3783 - categorical_accuracy: 0.5113
 - test_f1: 0.395690 - test_precision: 0.402937 - test_recall 0.452443
Model: "AccelerationEncoder"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_2 (InputLayer)         [(None, 192, 48, 1)]      0         
_________________________________________________________________
accBatch1 (BatchNormalizatio (None, 192, 48, 1)        4         
_________________________________________________________________
zero_padding2d_2 (ZeroPaddin (None, 194, 50, 1)        0         
_________________________________________________________________
accConv1 (Conv2D)            (None, 192, 48, 16)       160       
_________________________________________________________________
accBatch2 (BatchNormalizatio (None, 192, 48, 16)       64        
_________________________________________________________________
re_lu_5 (ReLU)               (None, 192, 48, 16)       0         
_________________________________________________________________
max_pooling2d_3 (MaxPooling2 (None, 96, 24, 16)        0         
_________________________________________________________________
zero_padding2d_3 (ZeroPaddin (None, 98, 26, 16)        0         
_________________________________________________________________
accConv2 (Conv2D)            (None, 96, 24, 32)        4640      
_________________________________________________________________
accBatch3 (BatchNormalizatio (None, 96, 24, 32)        128       
_________________________________________________________________
re_lu_6 (ReLU)               (None, 96, 24, 32)        0         
_________________________________________________________________
max_pooling2d_4 (MaxPooling2 (None, 48, 12, 32)        0         
_________________________________________________________________
accConv3 (Conv2D)            (None, 46, 10, 64)        18496     
_________________________________________________________________
accBatch4 (BatchNormalizatio (None, 46, 10, 64)        256       
_________________________________________________________________
re_lu_7 (ReLU)               (None, 46, 10, 64)        0         
_________________________________________________________________
max_pooling2d_5 (MaxPooling2 (None, 23, 5, 64)         0         
_________________________________________________________________
flatten_1 (Flatten)          (None, 7360)              0         
_________________________________________________________________
accDense1 (Dense)            (None, 128)               942208    
_________________________________________________________________
accBatch5 (BatchNormalizatio (None, 128)               512       
_________________________________________________________________
re_lu_8 (ReLU)               (None, 128)               0         
_________________________________________________________________
accDense2 (Dense)            (None, 256)               33024     
_________________________________________________________________
accBatch6 (BatchNormalizatio (None, 256)               1024      
_________________________________________________________________
re_lu_9 (ReLU)               (None, 256)               0         
=================================================================
Total params: 1,000,516
Trainable params: 0
Non-trainable params: 1,000,516
_________________________________________________________________
Model: "LocationEncoder"
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_3 (InputLayer)            [(None, 10, 2)]      0                                            
__________________________________________________________________________________________________
maskLayer1 (Masking)            (None, 10, 2)        0           input_3[0][0]                    
__________________________________________________________________________________________________
locBatch (BatchNormalization)   (None, 10, 2)        8           maskLayer1[0][0]                 
__________________________________________________________________________________________________
locLSTM (LSTM)                  (None, 128)          67072       locBatch[0][0]                   
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 128)          0           locLSTM[0][0]                    
__________________________________________________________________________________________________
input_4 (InputLayer)            [(None, 5)]          0                                            
__________________________________________________________________________________________________
tf.concat (TFOpLambda)          (None, 133)          0           dropout_6[0][0]                  
                                                                 input_4[0][0]                    
__________________________________________________________________________________________________
locDense1 (Dense)               (None, 128)          17152       tf.concat[0][0]                  
__________________________________________________________________________________________________
locBatch1 (BatchNormalization)  (None, 128)          512         locDense1[0][0]                  
__________________________________________________________________________________________________
mask_relu (MaskRelu)            (None, 128)          0           locBatch1[0][0]                  
__________________________________________________________________________________________________
dropout_7 (Dropout)             (None, 128)          0           mask_relu[0][0]                  
__________________________________________________________________________________________________
locDense2 (Dense)               (None, 64)           8256        dropout_7[0][0]                  
__________________________________________________________________________________________________
locBatch2 (BatchNormalization)  (None, 64)           256         locDense2[0][0]                  
__________________________________________________________________________________________________
mask_relu_1 (MaskRelu)          (None, 64)           0           locBatch2[0][0]                  
__________________________________________________________________________________________________
dropout_8 (Dropout)             (None, 64)           0           mask_relu_1[0][0]                
__________________________________________________________________________________________________
locDense3 (Dense)               (None, 256)          16640       dropout_8[0][0]                  
__________________________________________________________________________________________________
locBatch3 (BatchNormalization)  (None, 256)          1024        locDense3[0][0]                  
__________________________________________________________________________________________________
mask_relu_2 (MaskRelu)          (None, 256)          0           locBatch3[0][0]                  
__________________________________________________________________________________________________
tf.math.equal (TFOpLambda)      (None, 5)            0           input_4[0][0]                    
__________________________________________________________________________________________________
dropout_9 (Dropout)             (None, 256)          0           mask_relu_2[0][0]                
__________________________________________________________________________________________________
tf.math.reduce_all (TFOpLambda) (None, 1)            0           tf.math.equal[0][0]              
__________________________________________________________________________________________________
tf.compat.v1.shape (TFOpLambda) (2,)                 0           tf.math.reduce_all[0][0]         
__________________________________________________________________________________________________
tf.zeros_like (TFOpLambda)      (None, 256)          0           dropout_9[0][0]                  
__________________________________________________________________________________________________
tf.concat_1 (TFOpLambda)        (2,)                 0           tf.compat.v1.shape[0][0]         
__________________________________________________________________________________________________
tf.compat.v1.shape_1 (TFOpLambd (2,)                 0           tf.zeros_like[0][0]              
__________________________________________________________________________________________________
tf.math.subtract (TFOpLambda)   (2,)                 0           tf.compat.v1.shape_1[0][0]       
                                                                 tf.concat_1[0][0]                
__________________________________________________________________________________________________
tf.math.greater (TFOpLambda)    (2,)                 0           tf.math.subtract[0][0]           
__________________________________________________________________________________________________
tf.ones_like_1 (TFOpLambda)     (2,)                 0           tf.compat.v1.shape_1[0][0]       
__________________________________________________________________________________________________
tf.reshape (TFOpLambda)         (None, 1)            0           tf.math.reduce_all[0][0]         
                                                                 tf.concat_1[0][0]                
__________________________________________________________________________________________________
tf.where (TFOpLambda)           (2,)                 0           tf.math.greater[0][0]            
                                                                 tf.compat.v1.shape_1[0][0]       
                                                                 tf.ones_like_1[0][0]             
__________________________________________________________________________________________________
tf.tile (TFOpLambda)            (None, None)         0           tf.reshape[0][0]                 
                                                                 tf.where[0][0]                   
__________________________________________________________________________________________________
tf.ones_like (TFOpLambda)       (None, 256)          0           dropout_9[0][0]                  
__________________________________________________________________________________________________
tf.where_1 (TFOpLambda)         (None, 256)          0           tf.tile[0][0]                    
                                                                 tf.zeros_like[0][0]              
                                                                 tf.ones_like[0][0]               
__________________________________________________________________________________________________
tf.math.multiply (TFOpLambda)   (None, 256)          0           dropout_9[0][0]                  
                                                                 tf.where_1[0][0]                 
==================================================================================================
Total params: 110,920
Trainable params: 110,020
Non-trainable params: 900
__________________________________________________________________________________________________
Model: "AttentionLayer"
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_5 (InputLayer)            [(None, 256)]        0                                            
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 128)          32896       input_5[0][0]                    
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 128)          32896       input_5[0][0]                    
__________________________________________________________________________________________________
tf.math.multiply_1 (TFOpLambda) (None, 128)          0           dense_1[0][0]                    
                                                                 dense_2[0][0]                    
__________________________________________________________________________________________________
dense_3 (Dense)                 (None, 1)            129         tf.math.multiply_1[0][0]         
==================================================================================================
Total params: 65,921
Trainable params: 65,921
Non-trainable params: 0
__________________________________________________________________________________________________
Model: "Classifier"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_6 (InputLayer)         [(None, 256)]             0         
_________________________________________________________________
dense_4 (Dense)              (None, 128)               32896     
_________________________________________________________________
batch_normalization (BatchNo (None, 128)               512       
_________________________________________________________________
re_lu_10 (ReLU)              (None, 128)               0         
_________________________________________________________________
dense_5 (Dense)              (None, 8)                 1032      
=================================================================
Total params: 34,440
Trainable params: 34,184
Non-trainable params: 256
_________________________________________________________________
None
Epoch 1/5
 1/38 [..............................] - ETA: 38:31 - Loss: 2.4699 - Accuracy: 0.1250 2/38 [>.............................] - ETA: 1:39 - Loss: 2.4946 - Accuracy: 0.1250  3/38 [=>............................] - ETA: 1:59 - Loss: 2.3947 - Accuracy: 0.1146 4/38 [==>...........................] - ETA: 1:37 - Loss: 2.4404 - Accuracy: 0.0938 5/38 [==>...........................] - ETA: 1:25 - Loss: 2.3649 - Accuracy: 0.1063 6/38 [===>..........................] - ETA: 1:17 - Loss: 2.3352 - Accuracy: 0.1094 7/38 [====>.........................] - ETA: 1:11 - Loss: 2.3129 - Accuracy: 0.1071 8/38 [=====>........................] - ETA: 1:00 - Loss: 2.2826 - Accuracy: 0.1172 9/38 [======>.......................] - ETA: 51s - Loss: 2.2777 - Accuracy: 0.1215 10/38 [======>.......................] - ETA: 44s - Loss: 2.2611 - Accuracy: 0.131211/38 [=======>......................] - ETA: 38s - Loss: 2.2494 - Accuracy: 0.139212/38 [========>.....................] - ETA: 34s - Loss: 2.2438 - Accuracy: 0.151013/38 [=========>....................] - ETA: 30s - Loss: 2.2311 - Accuracy: 0.151414/38 [==========>...................] - ETA: 26s - Loss: 2.2146 - Accuracy: 0.160715/38 [==========>...................] - ETA: 24s - Loss: 2.1947 - Accuracy: 0.166716/38 [===========>..................] - ETA: 21s - Loss: 2.1844 - Accuracy: 0.171917/38 [============>.................] - ETA: 19s - Loss: 2.1781 - Accuracy: 0.169118/38 [=============>................] - ETA: 17s - Loss: 2.1790 - Accuracy: 0.164919/38 [==============>...............] - ETA: 15s - Loss: 2.1712 - Accuracy: 0.164520/38 [==============>...............] - ETA: 14s - Loss: 2.1654 - Accuracy: 0.170321/38 [===============>..............] - ETA: 12s - Loss: 2.1564 - Accuracy: 0.175622/38 [================>.............] - ETA: 11s - Loss: 2.1439 - Accuracy: 0.186123/38 [=================>............] - ETA: 10s - Loss: 2.1333 - Accuracy: 0.194324/38 [=================>............] - ETA: 9s - Loss: 2.1301 - Accuracy: 0.1914 25/38 [==================>...........] - ETA: 8s - Loss: 2.1196 - Accuracy: 0.201326/38 [===================>..........] - ETA: 7s - Loss: 2.1072 - Accuracy: 0.209127/38 [====================>.........] - ETA: 6s - Loss: 2.0982 - Accuracy: 0.210628/38 [=====================>........] - ETA: 5s - Loss: 2.0857 - Accuracy: 0.216529/38 [=====================>........] - ETA: 4s - Loss: 2.0753 - Accuracy: 0.220930/38 [======================>.......] - ETA: 4s - Loss: 2.0665 - Accuracy: 0.227131/38 [=======================>......] - ETA: 3s - Loss: 2.0581 - Accuracy: 0.229832/38 [========================>.....] - ETA: 3s - Loss: 2.0526 - Accuracy: 0.232433/38 [=========================>....] - ETA: 2s - Loss: 2.0381 - Accuracy: 0.242434/38 [=========================>....] - ETA: 1s - Loss: 2.0277 - Accuracy: 0.250035/38 [==========================>...] - ETA: 1s - Loss: 2.0275 - Accuracy: 0.251836/38 [===========================>..] - ETA: 0s - Loss: 2.0147 - Accuracy: 0.260437/38 [============================>.] - ETA: 0s - Loss: 2.0069 - Accuracy: 0.267738/38 [==============================] - ETA: 0s - Loss: 1.9953 - Accuracy: 0.276338/38 [==============================] - 251s 5s/step - Loss: 1.9953 - Accuracy: 0.2763 - val_Loss: 1.7172 - val_Accuracy: 0.3868
 - val_f1: 0.278534 - val_precision: 0.338521 - val_recall: 0.374555

Epoch 00001: val_Loss improved from inf to 1.71724, saving model to training\saved_models\shl_MILattention_model.h5
Epoch 2/5
 1/38 [..............................] - ETA: 2s - Loss: 1.6196 - Accuracy: 0.4688 2/38 [>.............................] - ETA: 2s - Loss: 1.6402 - Accuracy: 0.5000 3/38 [=>............................] - ETA: 2s - Loss: 1.6085 - Accuracy: 0.5104 4/38 [==>...........................] - ETA: 2s - Loss: 1.6358 - Accuracy: 0.4766 5/38 [==>...........................] - ETA: 2s - Loss: 1.6570 - Accuracy: 0.4563 6/38 [===>..........................] - ETA: 2s - Loss: 1.6586 - Accuracy: 0.4531 7/38 [====>.........................] - ETA: 1s - Loss: 1.6470 - Accuracy: 0.4688 8/38 [=====>........................] - ETA: 2s - Loss: 1.6521 - Accuracy: 0.4648 9/38 [======>.......................] - ETA: 2s - Loss: 1.6338 - Accuracy: 0.479210/38 [======>.......................] - ETA: 2s - Loss: 1.6325 - Accuracy: 0.493811/38 [=======>......................] - ETA: 2s - Loss: 1.6195 - Accuracy: 0.497212/38 [========>.....................] - ETA: 1s - Loss: 1.6096 - Accuracy: 0.492213/38 [=========>....................] - ETA: 1s - Loss: 1.6016 - Accuracy: 0.504814/38 [==========>...................] - ETA: 1s - Loss: 1.5935 - Accuracy: 0.504515/38 [==========>...................] - ETA: 1s - Loss: 1.5777 - Accuracy: 0.510416/38 [===========>..................] - ETA: 1s - Loss: 1.5749 - Accuracy: 0.509817/38 [============>.................] - ETA: 1s - Loss: 1.5723 - Accuracy: 0.516518/38 [=============>................] - ETA: 1s - Loss: 1.5816 - Accuracy: 0.506919/38 [==============>...............] - ETA: 1s - Loss: 1.5783 - Accuracy: 0.501620/38 [==============>...............] - ETA: 1s - Loss: 1.5699 - Accuracy: 0.506321/38 [===============>..............] - ETA: 1s - Loss: 1.5585 - Accuracy: 0.511922/38 [================>.............] - ETA: 1s - Loss: 1.5533 - Accuracy: 0.514223/38 [=================>............] - ETA: 1s - Loss: 1.5512 - Accuracy: 0.516324/38 [=================>............] - ETA: 0s - Loss: 1.5408 - Accuracy: 0.524725/38 [==================>...........] - ETA: 0s - Loss: 1.5332 - Accuracy: 0.532526/38 [===================>..........] - ETA: 0s - Loss: 1.5285 - Accuracy: 0.534927/38 [====================>.........] - ETA: 0s - Loss: 1.5255 - Accuracy: 0.538228/38 [=====================>........] - ETA: 0s - Loss: 1.5231 - Accuracy: 0.539129/38 [=====================>........] - ETA: 0s - Loss: 1.5235 - Accuracy: 0.540930/38 [======================>.......] - ETA: 0s - Loss: 1.5157 - Accuracy: 0.544831/38 [=======================>......] - ETA: 0s - Loss: 1.5019 - Accuracy: 0.552432/38 [========================>.....] - ETA: 0s - Loss: 1.4925 - Accuracy: 0.558633/38 [=========================>....] - ETA: 0s - Loss: 1.4881 - Accuracy: 0.558734/38 [=========================>....] - ETA: 0s - Loss: 1.4922 - Accuracy: 0.557035/38 [==========================>...] - ETA: 0s - Loss: 1.4887 - Accuracy: 0.560736/38 [===========================>..] - ETA: 0s - Loss: 1.4856 - Accuracy: 0.560837/38 [============================>.] - ETA: 0s - Loss: 1.4806 - Accuracy: 0.562538/38 [==============================] - ETA: 0s - Loss: 1.4711 - Accuracy: 0.565838/38 [==============================] - 6s 169ms/step - Loss: 1.4711 - Accuracy: 0.5658 - val_Loss: 1.4362 - val_Accuracy: 0.5708
 - val_f1: 0.398801 - val_precision: 0.416901 - val_recall: 0.463889

Epoch 00002: val_Loss improved from 1.71724 to 1.43620, saving model to training\saved_models\shl_MILattention_model.h5
Epoch 3/5
 1/38 [..............................] - ETA: 2s - Loss: 1.3064 - Accuracy: 0.5625 2/38 [>.............................] - ETA: 2s - Loss: 1.2237 - Accuracy: 0.6250 3/38 [=>............................] - ETA: 2s - Loss: 1.1940 - Accuracy: 0.6667 4/38 [==>...........................] - ETA: 2s - Loss: 1.1834 - Accuracy: 0.6641 5/38 [==>...........................] - ETA: 2s - Loss: 1.1695 - Accuracy: 0.6875 6/38 [===>..........................] - ETA: 2s - Loss: 1.2031 - Accuracy: 0.6771 7/38 [====>.........................] - ETA: 2s - Loss: 1.2053 - Accuracy: 0.6741 8/38 [=====>........................] - ETA: 2s - Loss: 1.1740 - Accuracy: 0.6914 9/38 [======>.......................] - ETA: 1s - Loss: 1.1844 - Accuracy: 0.677110/38 [======>.......................] - ETA: 1s - Loss: 1.1795 - Accuracy: 0.678111/38 [=======>......................] - ETA: 1s - Loss: 1.1788 - Accuracy: 0.679012/38 [========>.....................] - ETA: 1s - Loss: 1.1766 - Accuracy: 0.677113/38 [=========>....................] - ETA: 1s - Loss: 1.2003 - Accuracy: 0.663514/38 [==========>...................] - ETA: 1s - Loss: 1.1854 - Accuracy: 0.669615/38 [==========>...................] - ETA: 1s - Loss: 1.1711 - Accuracy: 0.675016/38 [===========>..................] - ETA: 1s - Loss: 1.1555 - Accuracy: 0.681617/38 [============>.................] - ETA: 1s - Loss: 1.1628 - Accuracy: 0.678318/38 [=============>................] - ETA: 1s - Loss: 1.1569 - Accuracy: 0.680619/38 [==============>...............] - ETA: 1s - Loss: 1.1490 - Accuracy: 0.682620/38 [==============>...............] - ETA: 1s - Loss: 1.1557 - Accuracy: 0.681221/38 [===============>..............] - ETA: 1s - Loss: 1.1633 - Accuracy: 0.677122/38 [================>.............] - ETA: 1s - Loss: 1.1639 - Accuracy: 0.673323/38 [=================>............] - ETA: 0s - Loss: 1.1646 - Accuracy: 0.672624/38 [=================>............] - ETA: 0s - Loss: 1.1602 - Accuracy: 0.670625/38 [==================>...........] - ETA: 0s - Loss: 1.1594 - Accuracy: 0.663726/38 [===================>..........] - ETA: 0s - Loss: 1.1510 - Accuracy: 0.667127/38 [====================>.........] - ETA: 0s - Loss: 1.1505 - Accuracy: 0.666728/38 [=====================>........] - ETA: 0s - Loss: 1.1355 - Accuracy: 0.673029/38 [=====================>........] - ETA: 0s - Loss: 1.1349 - Accuracy: 0.673530/38 [======================>.......] - ETA: 0s - Loss: 1.1406 - Accuracy: 0.672931/38 [=======================>......] - ETA: 0s - Loss: 1.1340 - Accuracy: 0.675432/38 [========================>.....] - ETA: 0s - Loss: 1.1298 - Accuracy: 0.676833/38 [=========================>....] - ETA: 0s - Loss: 1.1240 - Accuracy: 0.679034/38 [=========================>....] - ETA: 0s - Loss: 1.1217 - Accuracy: 0.681135/38 [==========================>...] - ETA: 0s - Loss: 1.1207 - Accuracy: 0.682136/38 [===========================>..] - ETA: 0s - Loss: 1.1140 - Accuracy: 0.684937/38 [============================>.] - ETA: 0s - Loss: 1.1118 - Accuracy: 0.685038/38 [==============================] - ETA: 0s - Loss: 1.1100 - Accuracy: 0.683438/38 [==============================] - 6s 173ms/step - Loss: 1.1100 - Accuracy: 0.6834 - val_Loss: 1.2134 - val_Accuracy: 0.6886
 - val_f1: 0.515452 - val_precision: 0.542190 - val_recall: 0.573718

Epoch 00003: val_Loss improved from 1.43620 to 1.21339, saving model to training\saved_models\shl_MILattention_model.h5
Epoch 4/5
 1/38 [..............................] - ETA: 2s - Loss: 0.9119 - Accuracy: 0.7500 2/38 [>.............................] - ETA: 2s - Loss: 0.9895 - Accuracy: 0.7344 3/38 [=>............................] - ETA: 2s - Loss: 1.0119 - Accuracy: 0.7292 4/38 [==>...........................] - ETA: 2s - Loss: 0.9635 - Accuracy: 0.7266 5/38 [==>...........................] - ETA: 2s - Loss: 0.9702 - Accuracy: 0.7125 6/38 [===>..........................] - ETA: 2s - Loss: 0.9440 - Accuracy: 0.7240 7/38 [====>.........................] - ETA: 1s - Loss: 0.9447 - Accuracy: 0.7098 8/38 [=====>........................] - ETA: 1s - Loss: 0.9604 - Accuracy: 0.7031 9/38 [======>.......................] - ETA: 1s - Loss: 0.9505 - Accuracy: 0.704910/38 [======>.......................] - ETA: 1s - Loss: 0.9526 - Accuracy: 0.703111/38 [=======>......................] - ETA: 1s - Loss: 0.9459 - Accuracy: 0.707412/38 [========>.....................] - ETA: 1s - Loss: 0.9413 - Accuracy: 0.708313/38 [=========>....................] - ETA: 1s - Loss: 0.9382 - Accuracy: 0.709114/38 [==========>...................] - ETA: 1s - Loss: 0.9416 - Accuracy: 0.707615/38 [==========>...................] - ETA: 1s - Loss: 0.9392 - Accuracy: 0.710416/38 [===========>..................] - ETA: 1s - Loss: 0.9313 - Accuracy: 0.714817/38 [============>.................] - ETA: 1s - Loss: 0.9247 - Accuracy: 0.720618/38 [=============>................] - ETA: 1s - Loss: 0.9214 - Accuracy: 0.722219/38 [==============>...............] - ETA: 1s - Loss: 0.9200 - Accuracy: 0.723720/38 [==============>...............] - ETA: 1s - Loss: 0.9147 - Accuracy: 0.726621/38 [===============>..............] - ETA: 1s - Loss: 0.9153 - Accuracy: 0.723222/38 [================>.............] - ETA: 1s - Loss: 0.9182 - Accuracy: 0.724423/38 [=================>............] - ETA: 0s - Loss: 0.9156 - Accuracy: 0.724224/38 [=================>............] - ETA: 0s - Loss: 0.9244 - Accuracy: 0.724025/38 [==================>...........] - ETA: 0s - Loss: 0.9201 - Accuracy: 0.723726/38 [===================>..........] - ETA: 0s - Loss: 0.9257 - Accuracy: 0.722427/38 [====================>.........] - ETA: 0s - Loss: 0.9268 - Accuracy: 0.723428/38 [=====================>........] - ETA: 0s - Loss: 0.9232 - Accuracy: 0.723229/38 [=====================>........] - ETA: 0s - Loss: 0.9178 - Accuracy: 0.725230/38 [======================>.......] - ETA: 0s - Loss: 0.9143 - Accuracy: 0.724031/38 [=======================>......] - ETA: 0s - Loss: 0.9091 - Accuracy: 0.725832/38 [========================>.....] - ETA: 0s - Loss: 0.9061 - Accuracy: 0.728533/38 [=========================>....] - ETA: 0s - Loss: 0.9067 - Accuracy: 0.726334/38 [=========================>....] - ETA: 0s - Loss: 0.8998 - Accuracy: 0.730735/38 [==========================>...] - ETA: 0s - Loss: 0.8988 - Accuracy: 0.730436/38 [===========================>..] - ETA: 0s - Loss: 0.8905 - Accuracy: 0.732637/38 [============================>.] - ETA: 0s - Loss: 0.8864 - Accuracy: 0.734838/38 [==============================] - ETA: 0s - Loss: 0.8825 - Accuracy: 0.736838/38 [==============================] - 6s 164ms/step - Loss: 0.8825 - Accuracy: 0.7368 - val_Loss: 1.2335 - val_Accuracy: 0.6956
 - val_f1: 0.527176 - val_precision: 0.531436 - val_recall: 0.590559

Epoch 00004: val_Loss did not improve from 1.21339
Epoch 5/5
 1/38 [..............................] - ETA: 2s - Loss: 0.8229 - Accuracy: 0.7188 2/38 [>.............................] - ETA: 2s - Loss: 0.7143 - Accuracy: 0.7812 3/38 [=>............................] - ETA: 2s - Loss: 0.6783 - Accuracy: 0.7812 4/38 [==>...........................] - ETA: 2s - Loss: 0.7248 - Accuracy: 0.7734 5/38 [==>...........................] - ETA: 2s - Loss: 0.7557 - Accuracy: 0.7437 6/38 [===>..........................] - ETA: 1s - Loss: 0.7474 - Accuracy: 0.7604 7/38 [====>.........................] - ETA: 1s - Loss: 0.7416 - Accuracy: 0.7500 8/38 [=====>........................] - ETA: 1s - Loss: 0.7771 - Accuracy: 0.7422 9/38 [======>.......................] - ETA: 1s - Loss: 0.7853 - Accuracy: 0.746510/38 [======>.......................] - ETA: 1s - Loss: 0.7817 - Accuracy: 0.753111/38 [=======>......................] - ETA: 1s - Loss: 0.8059 - Accuracy: 0.741512/38 [========>.....................] - ETA: 1s - Loss: 0.8192 - Accuracy: 0.726613/38 [=========>....................] - ETA: 1s - Loss: 0.8211 - Accuracy: 0.728414/38 [==========>...................] - ETA: 1s - Loss: 0.8106 - Accuracy: 0.734415/38 [==========>...................] - ETA: 1s - Loss: 0.8163 - Accuracy: 0.733316/38 [===========>..................] - ETA: 1s - Loss: 0.8132 - Accuracy: 0.736317/38 [============>.................] - ETA: 1s - Loss: 0.8135 - Accuracy: 0.740818/38 [=============>................] - ETA: 1s - Loss: 0.8052 - Accuracy: 0.744819/38 [==============>...............] - ETA: 1s - Loss: 0.8033 - Accuracy: 0.743420/38 [==============>...............] - ETA: 1s - Loss: 0.8040 - Accuracy: 0.746921/38 [===============>..............] - ETA: 1s - Loss: 0.7952 - Accuracy: 0.751522/38 [================>.............] - ETA: 0s - Loss: 0.7965 - Accuracy: 0.755723/38 [=================>............] - ETA: 0s - Loss: 0.7992 - Accuracy: 0.754124/38 [=================>............] - ETA: 0s - Loss: 0.7983 - Accuracy: 0.752625/38 [==================>...........] - ETA: 0s - Loss: 0.7963 - Accuracy: 0.750026/38 [===================>..........] - ETA: 0s - Loss: 0.7974 - Accuracy: 0.750027/38 [====================>.........] - ETA: 0s - Loss: 0.7957 - Accuracy: 0.748828/38 [=====================>........] - ETA: 0s - Loss: 0.7884 - Accuracy: 0.751129/38 [=====================>........] - ETA: 0s - Loss: 0.7799 - Accuracy: 0.756530/38 [======================>.......] - ETA: 0s - Loss: 0.7864 - Accuracy: 0.755231/38 [=======================>......] - ETA: 0s - Loss: 0.7799 - Accuracy: 0.758132/38 [========================>.....] - ETA: 0s - Loss: 0.7771 - Accuracy: 0.759833/38 [=========================>....] - ETA: 0s - Loss: 0.7683 - Accuracy: 0.763334/38 [=========================>....] - ETA: 0s - Loss: 0.7588 - Accuracy: 0.765635/38 [==========================>...] - ETA: 0s - Loss: 0.7612 - Accuracy: 0.765236/38 [===========================>..] - ETA: 0s - Loss: 0.7557 - Accuracy: 0.765637/38 [============================>.] - ETA: 0s - Loss: 0.7586 - Accuracy: 0.763538/38 [==============================] - ETA: 0s - Loss: 0.7578 - Accuracy: 0.763238/38 [==============================] - 6s 165ms/step - Loss: 0.7578 - Accuracy: 0.7632 - val_Loss: 1.0974 - val_Accuracy: 0.7257
 - val_f1: 0.563513 - val_precision: 0.588630 - val_recall: 0.615073

Epoch 00005: val_Loss improved from 1.21339 to 1.09740, saving model to training\saved_models\shl_MILattention_model.h5
 - val_f1: 0.564231 - val_precision: 0.590787 - val_recall: 0.615433
