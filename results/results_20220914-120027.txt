Found Data
{'accBagSize': 3,
 'accBagStride': 400,
 'accDuration': 1200,
 'accStride': 400,
 'bagging': False,
 'day': 'all',
 'decimateTime': False,
 'dropnan': True,
 'dropnull': False,
 'dynamicWindow': True,
 'gpsSignal': False,
 'hardLabelling': False,
 'interpolateGaps': 3,
 'interpolationThreshold': True,
 'labelPosition': None,
 'labellingThreshold': None,
 'locBagSize': 1,
 'locBagStride': 1,
 'locDuration': 12,
 'locPosition': None,
 'locSampling': 'hop',
 'locStride': 1,
 'overlap': True,
 'pairThreshold': 30000,
 'path': 'E:\\SHL\\',
 'percentageThreshold': 0.6,
 'position': 'all',
 'randomStride': False,
 'sampling': 'decimation',
 'smpl_acc_period': 0.05,
 'smpl_loc_period': 60,
 'src_path': 'E:\\SHL\\srcData\\',
 'strideRange': [200, 600],
 'threshold': 10000,
 'useAccuracy': True,
 'user': 'all'}

{'FFT': False,
 'accBagPivot': None,
 'accBagSize': 3,
 'accEpochs': 160,
 'acc_fusion': 'Frequency',
 'acc_model': 'ResNet',
 'acc_norm_aug_params': [],
 'acc_norm_augmentation': [],
 'acc_signals': ['Acc_x', 'Acc_y', 'Acc_z', 'Acc_norm'],
 'acc_xyz_aug_params': [],
 'acc_xyz_augmentation': [],
 'bagStride': 1,
 'classifier_layers': True,
 'containLabel': False,
 'dimension': 128,
 'drop_run': False,
 'epochs': 80,
 'finetuning': False,
 'finetuning_epochs': 5,
 'finetuning_learning_rate': 6e-07,
 'finetuning_lr_factor': 0.1,
 'fusion': 'MIL',
 'gpsPosition': 'Hand',
 'haversine_distance': True,
 'highpass_filter': False,
 'input_dropout': 0.3,
 'interp_std_factor': 0.3,
 'interpolation': 'quadratic',
 'intersect': True,
 'learning_rate': 0.0001,
 'locBagPivot': None,
 'locBagSize': 1,
 'locEpochs': 200,
 'loc_features': ['TotalWalk', 'Mean', 'Var'],
 'loc_fusion': 'LSTM',
 'loc_signals': ['Velocity', 'Acceleration'],
 'location_interp_aug': False,
 'location_noise': True,
 'loss_function': 'crossentropy',
 'mask': -10000000,
 'noise_std_factor': 0.5,
 'nullLoc': 'masking',
 'padding_method': 'masking',
 'padding_threshold': 12,
 'pair_threshold': 300000,
 'positions': ['Torso', 'Hips', 'Bag', 'Hand'],
 'post_processing': True,
 'post_processing_method': 'LSTM',
 'random_tree': False,
 'second_order': True,
 'seperate_MIL': False,
 'simCLR': 'none',
 'simCLR_criterion': 'augmentation',
 'simCLR_finetuning': True,
 'simCLRepochs': 120,
 'specto_aug': ['frequencyMask', 'timeMask'],
 'spectograms': True,
 'stratify': 'concentrated',
 'testBatchSize': 32,
 'test_user': 1,
 'trainBatchSize': 32,
 'transfer_learning_acc': 'train',
 'transfer_learning_loc': 'none',
 'use_gated': True,
 'valBatchSize': 32,
 'val_percentage': 0.15,
 'val_size': 2000}

3 1 1
Found Data
Model: "AccelerationEncoder"
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            [(None, 192, 48, 1)] 0                                            
__________________________________________________________________________________________________
Res1Batch1 (BatchNormalization) (None, 192, 48, 1)   4           input_1[0][0]                    
__________________________________________________________________________________________________
Res1Conv1 (Conv2D)              (None, 96, 24, 16)   160         Res1Batch1[0][0]                 
__________________________________________________________________________________________________
Res1Batch2 (BatchNormalization) (None, 96, 24, 16)   64          Res1Conv1[0][0]                  
__________________________________________________________________________________________________
re_lu (ReLU)                    (None, 96, 24, 16)   0           Res1Batch2[0][0]                 
__________________________________________________________________________________________________
Res1Conv2 (Conv2D)              (None, 96, 24, 16)   2320        re_lu[0][0]                      
__________________________________________________________________________________________________
Res1Batch3 (BatchNormalization) (None, 96, 24, 16)   64          Res1Conv2[0][0]                  
__________________________________________________________________________________________________
add (Add)                       (None, 96, 24, 16)   0           re_lu[0][0]                      
                                                                 Res1Batch3[0][0]                 
__________________________________________________________________________________________________
re_lu_1 (ReLU)                  (None, 96, 24, 16)   0           add[0][0]                        
__________________________________________________________________________________________________
Res1Conv3 (Conv2D)              (None, 96, 24, 16)   2320        re_lu_1[0][0]                    
__________________________________________________________________________________________________
Res1Batch4 (BatchNormalization) (None, 96, 24, 16)   64          Res1Conv3[0][0]                  
__________________________________________________________________________________________________
Res1ConvIdentity (Conv2D)       (None, 96, 24, 16)   32          Res1Batch1[0][0]                 
__________________________________________________________________________________________________
add_1 (Add)                     (None, 96, 24, 16)   0           re_lu[0][0]                      
                                                                 re_lu_1[0][0]                    
                                                                 Res1Batch4[0][0]                 
__________________________________________________________________________________________________
add_2 (Add)                     (None, 96, 24, 16)   0           Res1ConvIdentity[0][0]           
                                                                 add_1[0][0]                      
__________________________________________________________________________________________________
re_lu_2 (ReLU)                  (None, 96, 24, 16)   0           add_2[0][0]                      
__________________________________________________________________________________________________
Res2Batch1 (BatchNormalization) (None, 96, 24, 16)   64          re_lu_2[0][0]                    
__________________________________________________________________________________________________
Res2Conv1 (Conv2D)              (None, 48, 12, 32)   4640        Res2Batch1[0][0]                 
__________________________________________________________________________________________________
Res2Batch2 (BatchNormalization) (None, 48, 12, 32)   128         Res2Conv1[0][0]                  
__________________________________________________________________________________________________
re_lu_3 (ReLU)                  (None, 48, 12, 32)   0           Res2Batch2[0][0]                 
__________________________________________________________________________________________________
Res2Conv2 (Conv2D)              (None, 48, 12, 32)   9248        re_lu_3[0][0]                    
__________________________________________________________________________________________________
Res2Batch3 (BatchNormalization) (None, 48, 12, 32)   128         Res2Conv2[0][0]                  
__________________________________________________________________________________________________
add_3 (Add)                     (None, 48, 12, 32)   0           re_lu_3[0][0]                    
                                                                 Res2Batch3[0][0]                 
__________________________________________________________________________________________________
re_lu_4 (ReLU)                  (None, 48, 12, 32)   0           add_3[0][0]                      
__________________________________________________________________________________________________
Res2Conv3 (Conv2D)              (None, 48, 12, 32)   9248        re_lu_4[0][0]                    
__________________________________________________________________________________________________
Res2Batch4 (BatchNormalization) (None, 48, 12, 32)   128         Res2Conv3[0][0]                  
__________________________________________________________________________________________________
Res2ConvIdentity (Conv2D)       (None, 48, 12, 32)   544         Res2Batch1[0][0]                 
__________________________________________________________________________________________________
add_4 (Add)                     (None, 48, 12, 32)   0           re_lu_3[0][0]                    
                                                                 re_lu_4[0][0]                    
                                                                 Res2Batch4[0][0]                 
__________________________________________________________________________________________________
add_5 (Add)                     (None, 48, 12, 32)   0           Res2ConvIdentity[0][0]           
                                                                 add_4[0][0]                      
__________________________________________________________________________________________________
re_lu_5 (ReLU)                  (None, 48, 12, 32)   0           add_5[0][0]                      
__________________________________________________________________________________________________
Res3Batch1 (BatchNormalization) (None, 48, 12, 32)   128         re_lu_5[0][0]                    
__________________________________________________________________________________________________
Res3Conv1 (Conv2D)              (None, 24, 6, 64)    18496       Res3Batch1[0][0]                 
__________________________________________________________________________________________________
Res3Batch2 (BatchNormalization) (None, 24, 6, 64)    256         Res3Conv1[0][0]                  
__________________________________________________________________________________________________
re_lu_6 (ReLU)                  (None, 24, 6, 64)    0           Res3Batch2[0][0]                 
__________________________________________________________________________________________________
Res3Conv2 (Conv2D)              (None, 24, 6, 64)    36928       re_lu_6[0][0]                    
__________________________________________________________________________________________________
Res3Batch3 (BatchNormalization) (None, 24, 6, 64)    256         Res3Conv2[0][0]                  
__________________________________________________________________________________________________
add_6 (Add)                     (None, 24, 6, 64)    0           re_lu_6[0][0]                    
                                                                 Res3Batch3[0][0]                 
__________________________________________________________________________________________________
re_lu_7 (ReLU)                  (None, 24, 6, 64)    0           add_6[0][0]                      
__________________________________________________________________________________________________
Res3Conv3 (Conv2D)              (None, 24, 6, 64)    36928       re_lu_7[0][0]                    
__________________________________________________________________________________________________
Res3Batch4 (BatchNormalization) (None, 24, 6, 64)    256         Res3Conv3[0][0]                  
__________________________________________________________________________________________________
Res3ConvIdentity (Conv2D)       (None, 24, 6, 64)    2112        Res3Batch1[0][0]                 
__________________________________________________________________________________________________
add_7 (Add)                     (None, 24, 6, 64)    0           re_lu_6[0][0]                    
                                                                 re_lu_7[0][0]                    
                                                                 Res3Batch4[0][0]                 
__________________________________________________________________________________________________
add_8 (Add)                     (None, 24, 6, 64)    0           Res3ConvIdentity[0][0]           
                                                                 add_7[0][0]                      
__________________________________________________________________________________________________
re_lu_8 (ReLU)                  (None, 24, 6, 64)    0           add_8[0][0]                      
__________________________________________________________________________________________________
Res4Batch1 (BatchNormalization) (None, 24, 6, 64)    256         re_lu_8[0][0]                    
__________________________________________________________________________________________________
Res4Conv1 (Conv2D)              (None, 12, 3, 128)   73856       Res4Batch1[0][0]                 
__________________________________________________________________________________________________
Res4Batch2 (BatchNormalization) (None, 12, 3, 128)   512         Res4Conv1[0][0]                  
__________________________________________________________________________________________________
re_lu_9 (ReLU)                  (None, 12, 3, 128)   0           Res4Batch2[0][0]                 
__________________________________________________________________________________________________
Res4Conv2 (Conv2D)              (None, 12, 3, 128)   147584      re_lu_9[0][0]                    
__________________________________________________________________________________________________
Res4Batch3 (BatchNormalization) (None, 12, 3, 128)   512         Res4Conv2[0][0]                  
__________________________________________________________________________________________________
add_9 (Add)                     (None, 12, 3, 128)   0           re_lu_9[0][0]                    
                                                                 Res4Batch3[0][0]                 
__________________________________________________________________________________________________
re_lu_10 (ReLU)                 (None, 12, 3, 128)   0           add_9[0][0]                      
__________________________________________________________________________________________________
Res4Conv3 (Conv2D)              (None, 12, 3, 128)   147584      re_lu_10[0][0]                   
__________________________________________________________________________________________________
Res4Batch4 (BatchNormalization) (None, 12, 3, 128)   512         Res4Conv3[0][0]                  
__________________________________________________________________________________________________
Res4ConvIdentity (Conv2D)       (None, 12, 3, 128)   8320        Res4Batch1[0][0]                 
__________________________________________________________________________________________________
add_10 (Add)                    (None, 12, 3, 128)   0           re_lu_9[0][0]                    
                                                                 re_lu_10[0][0]                   
                                                                 Res4Batch4[0][0]                 
__________________________________________________________________________________________________
add_11 (Add)                    (None, 12, 3, 128)   0           Res4ConvIdentity[0][0]           
                                                                 add_10[0][0]                     
__________________________________________________________________________________________________
re_lu_11 (ReLU)                 (None, 12, 3, 128)   0           add_11[0][0]                     
__________________________________________________________________________________________________
flatten (Flatten)               (None, 4608)         0           re_lu_11[0][0]                   
__________________________________________________________________________________________________
dropout (Dropout)               (None, 4608)         0           flatten[0][0]                    
__________________________________________________________________________________________________
accDense1 (Dense)               (None, 128)          589952      dropout[0][0]                    
__________________________________________________________________________________________________
re_lu_12 (ReLU)                 (None, 128)          0           accDense1[0][0]                  
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 128)          0           re_lu_12[0][0]                   
__________________________________________________________________________________________________
accDense2 (Dense)               (None, 256)          33024       dropout_1[0][0]                  
__________________________________________________________________________________________________
re_lu_13 (ReLU)                 (None, 256)          0           accDense2[0][0]                  
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 256)          0           re_lu_13[0][0]                   
__________________________________________________________________________________________________
dense (Dense)                   (None, 8)            2056        dropout_2[0][0]                  
==================================================================================================
Total params: 1,128,684
Trainable params: 1,127,018
Non-trainable params: 1,666
__________________________________________________________________________________________________
None
Epoch 1/160
  1/765 [..............................] - ETA: 6:53:45 - loss: 6.3730 - categorical_accuracy: 0.0938  2/765 [..............................] - ETA: 8:20 - loss: 6.4334 - categorical_accuracy: 0.1250     3/765 [..............................] - ETA: 9:16 - loss: 5.9371 - categorical_accuracy: 0.1458  4/765 [..............................] - ETA: 9:38 - loss: 5.8782 - categorical_accuracy: 0.1250  5/765 [..............................] - ETA: 9:53 - loss: 5.6844 - categorical_accuracy: 0.1250  6/765 [..............................] - ETA: 9:58 - loss: 5.4527 - categorical_accuracy: 0.1354  7/765 [..............................] - ETA: 10:02 - loss: 5.2716 - categorical_accuracy: 0.1473  8/765 [..............................] - ETA: 10:05 - loss: 5.2624 - categorical_accuracy: 0.1406  9/765 [..............................] - ETA: 10:20 - loss: 5.2157 - categorical_accuracy: 0.1354 10/765 [..............................] - ETA: 10:35 - loss: 5.0665 - categorical_accuracy: 0.1281 11/765 [..............................] - ETA: 10:32 - loss: 4.8641 - categorical_accuracy: 0.1307 12/765 [..............................] - ETA: 10:30 - loss: 4.7690 - categorical_accuracy: 0.1276 13/765 [..............................] - ETA: 10:27 - loss: 4.6730 - categorical_accuracy: 0.1298 14/765 [..............................] - ETA: 10:25 - loss: 4.5468 - categorical_accuracy: 0.1272 15/765 [..............................] - ETA: 10:24 - loss: 4.5044 - categorical_accuracy: 0.1271 16/765 [..............................] - ETA: 10:23 - loss: 4.3856 - categorical_accuracy: 0.1270 17/765 [..............................] - ETA: 10:21 - loss: 4.3402 - categorical_accuracy: 0.1287 18/765 [..............................] - ETA: 10:17 - loss: 4.2766 - categorical_accuracy: 0.1285 19/765 [..............................] - ETA: 10:16 - loss: 4.2140 - categorical_accuracy: 0.1299 20/765 [..............................] - ETA: 10:14 - loss: 4.1761 - categorical_accuracy: 0.1281 21/765 [..............................] - ETA: 10:13 - loss: 4.1178 - categorical_accuracy: 0.1265 22/765 [..............................] - ETA: 10:10 - loss: 4.0775 - categorical_accuracy: 0.1222 23/765 [..............................] - ETA: 10:10 - loss: 4.0151 - categorical_accuracy: 0.1277 24/765 [..............................] - ETA: 10:09 - loss: 3.9455 - categorical_accuracy: 0.1341 25/765 [..............................] - ETA: 10:10 - loss: 3.8818 - categorical_accuracy: 0.1388 26/765 [>.............................] - ETA: 10:09 - loss: 3.8366 - categorical_accuracy: 0.1382 27/765 [>.............................] - ETA: 10:09 - loss: 3.7905 - categorical_accuracy: 0.1389 28/765 [>.............................] - ETA: 10:16 - loss: 3.7516 - categorical_accuracy: 0.1406 29/765 [>.............................] - ETA: 10:14 - loss: 3.6924 - categorical_accuracy: 0.1466 30/765 [>.............................] - ETA: 10:14 - loss: 3.6615 - categorical_accuracy: 0.1479 31/765 [>.............................] - ETA: 10:15 - loss: 3.6214 - categorical_accuracy: 0.1512 32/765 [>.............................] - ETA: 10:15 - loss: 3.5811 - categorical_accuracy: 0.1553 33/765 [>.............................] - ETA: 10:15 - loss: 3.5373 - categorical_accuracy: 0.1581 34/765 [>.............................] - ETA: 10:14 - loss: 3.5027 - categorical_accuracy: 0.1627 35/765 [>.............................] - ETA: 10:13 - loss: 3.4693 - categorical_accuracy: 0.1643 36/765 [>.............................] - ETA: 10:12 - loss: 3.4370 - categorical_accuracy: 0.1641 37/765 [>.............................] - ETA: 10:11 - loss: 3.4127 - categorical_accuracy: 0.1639 38/765 [>.............................] - ETA: 10:10 - loss: 3.3874 - categorical_accuracy: 0.1637 39/765 [>.............................] - ETA: 10:08 - loss: 3.3575 - categorical_accuracy: 0.1651 40/765 [>.............................] - ETA: 10:07 - loss: 3.3294 - categorical_accuracy: 0.1688 41/765 [>.............................] - ETA: 10:06 - loss: 3.2988 - categorical_accuracy: 0.1707 42/765 [>.............................] - ETA: 10:05 - loss: 3.2718 - categorical_accuracy: 0.1704 43/765 [>.............................] - ETA: 10:04 - loss: 3.2442 - categorical_accuracy: 0.1730 44/765 [>.............................] - ETA: 10:03 - loss: 3.2171 - categorical_accuracy: 0.1761 45/765 [>.............................] - ETA: 10:02 - loss: 3.1922 - categorical_accuracy: 0.1778 46/765 [>.............................] - ETA: 10:01 - loss: 3.1736 - categorical_accuracy: 0.1780 47/765 [>.............................] - ETA: 10:00 - loss: 3.1531 - categorical_accuracy: 0.1789 48/765 [>.............................] - ETA: 9:59 - loss: 3.1463 - categorical_accuracy: 0.1758  49/765 [>.............................] - ETA: 9:58 - loss: 3.1287 - categorical_accuracy: 0.1747 50/765 [>.............................] - ETA: 9:57 - loss: 3.1132 - categorical_accuracy: 0.1737 51/765 [=>............................] - ETA: 9:56 - loss: 3.0884 - categorical_accuracy: 0.1734 52/765 [=>............................] - ETA: 9:55 - loss: 3.0703 - categorical_accuracy: 0.1731 53/765 [=>............................] - ETA: 9:55 - loss: 3.0564 - categorical_accuracy: 0.1728 54/765 [=>............................] - ETA: 9:54 - loss: 3.0405 - categorical_accuracy: 0.1719 55/765 [=>............................] - ETA: 9:53 - loss: 3.0252 - categorical_accuracy: 0.1739 56/765 [=>............................] - ETA: 9:52 - loss: 3.0104 - categorical_accuracy: 0.1741 57/765 [=>............................] - ETA: 9:51 - loss: 2.9918 - categorical_accuracy: 0.1771 58/765 [=>............................] - ETA: 9:51 - loss: 2.9745 - categorical_accuracy: 0.1789 59/765 [=>............................] - ETA: 9:50 - loss: 2.9620 - categorical_accuracy: 0.1790 60/765 [=>............................] - ETA: 9:50 - loss: 2.9524 - categorical_accuracy: 0.1786 61/765 [=>............................] - ETA: 9:49 - loss: 2.9404 - categorical_accuracy: 0.1808 62/765 [=>............................] - ETA: 9:47 - loss: 2.9326 - categorical_accuracy: 0.1809 63/765 [=>............................] - ETA: 9:46 - loss: 2.9209 - categorical_accuracy: 0.1801 64/765 [=>............................] - ETA: 9:45 - loss: 2.9067 - categorical_accuracy: 0.1802 65/765 [=>............................] - ETA: 9:45 - loss: 2.8956 - categorical_accuracy: 0.1813 66/765 [=>............................] - ETA: 9:45 - loss: 2.8832 - categorical_accuracy: 0.1828 67/765 [=>............................] - ETA: 9:44 - loss: 2.8707 - categorical_accuracy: 0.1819 68/765 [=>............................] - ETA: 9:43 - loss: 2.8611 - categorical_accuracy: 0.1820 69/765 [=>............................] - ETA: 9:42 - loss: 2.8490 - categorical_accuracy: 0.1848 70/765 [=>............................] - ETA: 9:47 - loss: 2.8395 - categorical_accuracy: 0.1848 71/765 [=>............................] - ETA: 9:47 - loss: 2.8307 - categorical_accuracy: 0.1844 72/765 [=>............................] - ETA: 9:46 - loss: 2.8203 - categorical_accuracy: 0.1845 73/765 [=>............................] - ETA: 9:45 - loss: 2.8086 - categorical_accuracy: 0.1862 74/765 [=>............................] - ETA: 9:44 - loss: 2.7973 - categorical_accuracy: 0.1871 75/765 [=>............................] - ETA: 9:43 - loss: 2.7900 - categorical_accuracy: 0.1875 76/765 [=>............................] - ETA: 9:42 - loss: 2.7785 - categorical_accuracy: 0.1883 77/765 [==>...........................] - ETA: 9:41 - loss: 2.7669 - categorical_accuracy: 0.1895 78/765 [==>...........................] - ETA: 9:40 - loss: 2.7570 - categorical_accuracy: 0.1907 79/765 [==>...........................] - ETA: 9:39 - loss: 2.7485 - categorical_accuracy: 0.1915 80/765 [==>...........................] - ETA: 9:38 - loss: 2.7404 - categorical_accuracy: 0.1906 81/765 [==>...........................] - ETA: 9:37 - loss: 2.7325 - categorical_accuracy: 0.1902 82/765 [==>...........................] - ETA: 9:36 - loss: 2.7240 - categorical_accuracy: 0.1909 83/765 [==>...........................] - ETA: 9:36 - loss: 2.7154 - categorical_accuracy: 0.1924 84/765 [==>...........................] - ETA: 9:35 - loss: 2.7098 - categorical_accuracy: 0.1920 85/765 [==>...........................] - ETA: 9:34 - loss: 2.7040 - categorical_accuracy: 0.1915 86/765 [==>...........................] - ETA: 9:34 - loss: 2.6959 - categorical_accuracy: 0.1915 87/765 [==>...........................] - ETA: 9:33 - loss: 2.6882 - categorical_accuracy: 0.1915 88/765 [==>...........................] - ETA: 9:32 - loss: 2.6803 - categorical_accuracy: 0.1914 89/765 [==>...........................] - ETA: 9:31 - loss: 2.6724 - categorical_accuracy: 0.1921 90/765 [==>...........................] - ETA: 9:30 - loss: 2.6651 - categorical_accuracy: 0.1931 91/765 [==>...........................] - ETA: 9:29 - loss: 2.6584 - categorical_accuracy: 0.1930 92/765 [==>...........................] - ETA: 9:28 - loss: 2.6511 - categorical_accuracy: 0.1929 93/765 [==>...........................] - ETA: 9:27 - loss: 2.6448 - categorical_accuracy: 0.1929 94/765 [==>...........................] - ETA: 9:26 - loss: 2.6368 - categorical_accuracy: 0.1941 95/765 [==>...........................] - ETA: 9:25 - loss: 2.6293 - categorical_accuracy: 0.1954 96/765 [==>...........................] - ETA: 9:23 - loss: 2.6241 - categorical_accuracy: 0.1950 97/765 [==>...........................] - ETA: 9:22 - loss: 2.6164 - categorical_accuracy: 0.1956 98/765 [==>...........................] - ETA: 9:21 - loss: 2.6098 - categorical_accuracy: 0.1961 99/765 [==>...........................] - ETA: 9:20 - loss: 2.6037 - categorical_accuracy: 0.1960100/765 [==>...........................] - ETA: 9:19 - loss: 2.5974 - categorical_accuracy: 0.1972101/765 [==>...........................] - ETA: 9:18 - loss: 2.5939 - categorical_accuracy: 0.1962102/765 [===>..........................] - ETA: 9:16 - loss: 2.5865 - categorical_accuracy: 0.1979103/765 [===>..........................] - ETA: 9:15 - loss: 2.5805 - categorical_accuracy: 0.1987104/765 [===>..........................] - ETA: 9:14 - loss: 2.5743 - categorical_accuracy: 0.1992105/765 [===>..........................] - ETA: 9:13 - loss: 2.5693 - categorical_accuracy: 0.1991106/765 [===>..........................] - ETA: 9:12 - loss: 2.5628 - categorical_accuracy: 0.2008107/765 [===>..........................] - ETA: 9:11 - loss: 2.5560 - categorical_accuracy: 0.2027108/765 [===>..........................] - ETA: 9:10 - loss: 2.5506 - categorical_accuracy: 0.2028109/765 [===>..........................] - ETA: 9:08 - loss: 2.5459 - categorical_accuracy: 0.2030110/765 [===>..........................] - ETA: 9:07 - loss: 2.5392 - categorical_accuracy: 0.2037111/765 [===>..........................] - ETA: 9:06 - loss: 2.5344 - categorical_accuracy: 0.2035112/765 [===>..........................] - ETA: 9:05 - loss: 2.5276 - categorical_accuracy: 0.2051113/765 [===>..........................] - ETA: 9:04 - loss: 2.5240 - categorical_accuracy: 0.2055114/765 [===>..........................] - ETA: 9:03 - loss: 2.5174 - categorical_accuracy: 0.2064115/765 [===>..........................] - ETA: 9:02 - loss: 2.5143 - categorical_accuracy: 0.2065116/765 [===>..........................] - ETA: 9:01 - loss: 2.5108 - categorical_accuracy: 0.2061117/765 [===>..........................] - ETA: 8:59 - loss: 2.5068 - categorical_accuracy: 0.2065118/765 [===>..........................] - ETA: 8:58 - loss: 2.5015 - categorical_accuracy: 0.2066119/765 [===>..........................] - ETA: 8:57 - loss: 2.4984 - categorical_accuracy: 0.2069120/765 [===>..........................] - ETA: 8:56 - loss: 2.4950 - categorical_accuracy: 0.2068121/765 [===>..........................] - ETA: 8:55 - loss: 2.4899 - categorical_accuracy: 0.2079122/765 [===>..........................] - ETA: 8:54 - loss: 2.4867 - categorical_accuracy: 0.2072123/765 [===>..........................] - ETA: 8:53 - loss: 2.4841 - categorical_accuracy: 0.2066124/765 [===>..........................] - ETA: 8:52 - loss: 2.4814 - categorical_accuracy: 0.2067125/765 [===>..........................] - ETA: 8:51 - loss: 2.4762 - categorical_accuracy: 0.2075126/765 [===>..........................] - ETA: 8:50 - loss: 2.4723 - categorical_accuracy: 0.2073127/765 [===>..........................] - ETA: 8:49 - loss: 2.4690 - categorical_accuracy: 0.2067128/765 [====>.........................] - ETA: 8:48 - loss: 2.4662 - categorical_accuracy: 0.2068129/765 [====>.........................] - ETA: 8:47 - loss: 2.4649 - categorical_accuracy: 0.2066130/765 [====>.........................] - ETA: 8:46 - loss: 2.4594 - categorical_accuracy: 0.2084131/765 [====>.........................] - ETA: 8:46 - loss: 2.4542 - categorical_accuracy: 0.2099132/765 [====>.........................] - ETA: 8:45 - loss: 2.4500 - categorical_accuracy: 0.2105133/765 [====>.........................] - ETA: 8:44 - loss: 2.4460 - categorical_accuracy: 0.2110134/765 [====>.........................] - ETA: 8:43 - loss: 2.4414 - categorical_accuracy: 0.2118135/765 [====>.........................] - ETA: 8:42 - loss: 2.4374 - categorical_accuracy: 0.2118136/765 [====>.........................] - ETA: 8:41 - loss: 2.4337 - categorical_accuracy: 0.2121137/765 [====>.........................] - ETA: 8:40 - loss: 2.4288 - categorical_accuracy: 0.2133138/765 [====>.........................] - ETA: 8:39 - loss: 2.4244 - categorical_accuracy: 0.2135139/765 [====>.........................] - ETA: 8:38 - loss: 2.4207 - categorical_accuracy: 0.2136140/765 [====>.........................] - ETA: 8:37 - loss: 2.4183 - categorical_accuracy: 0.2136141/765 [====>.........................] - ETA: 8:36 - loss: 2.4150 - categorical_accuracy: 0.2139142/765 [====>.........................] - ETA: 8:35 - loss: 2.4106 - categorical_accuracy: 0.2152143/765 [====>.........................] - ETA: 8:34 - loss: 2.4063 - categorical_accuracy: 0.2153144/765 [====>.........................] - ETA: 8:34 - loss: 2.4037 - categorical_accuracy: 0.2148145/765 [====>.........................] - ETA: 8:33 - loss: 2.4011 - categorical_accuracy: 0.2149146/765 [====>.........................] - ETA: 8:33 - loss: 2.3982 - categorical_accuracy: 0.2149147/765 [====>.........................] - ETA: 8:32 - loss: 2.3938 - categorical_accuracy: 0.2156148/765 [====>.........................] - ETA: 8:31 - loss: 2.3900 - categorical_accuracy: 0.2166149/765 [====>.........................] - ETA: 8:30 - loss: 2.3873 - categorical_accuracy: 0.2179150/765 [====>.........................] - ETA: 8:29 - loss: 2.3860 - categorical_accuracy: 0.2179151/765 [====>.........................] - ETA: 8:28 - loss: 2.3855 - categorical_accuracy: 0.2175152/765 [====>.........................] - ETA: 8:27 - loss: 2.3810 - categorical_accuracy: 0.2183153/765 [=====>........................] - ETA: 8:26 - loss: 2.3789 - categorical_accuracy: 0.2185154/765 [=====>........................] - ETA: 8:26 - loss: 2.3761 - categorical_accuracy: 0.2185155/765 [=====>........................] - ETA: 8:25 - loss: 2.3727 - categorical_accuracy: 0.2194156/765 [=====>........................] - ETA: 8:24 - loss: 2.3698 - categorical_accuracy: 0.2194157/765 [=====>........................] - ETA: 8:23 - loss: 2.3678 - categorical_accuracy: 0.2197158/765 [=====>........................] - ETA: 8:22 - loss: 2.3641 - categorical_accuracy: 0.2203159/765 [=====>........................] - ETA: 8:21 - loss: 2.3609 - categorical_accuracy: 0.2207160/765 [=====>........................] - ETA: 8:20 - loss: 2.3582 - categorical_accuracy: 0.2207161/765 [=====>........................] - ETA: 8:19 - loss: 2.3568 - categorical_accuracy: 0.2201162/765 [=====>........................] - ETA: 8:18 - loss: 2.3524 - categorical_accuracy: 0.2216163/765 [=====>........................] - ETA: 8:17 - loss: 2.3502 - categorical_accuracy: 0.2220164/765 [=====>........................] - ETA: 8:16 - loss: 2.3476 - categorical_accuracy: 0.2224165/765 [=====>........................] - ETA: 8:16 - loss: 2.3449 - categorical_accuracy: 0.2225166/765 [=====>........................] - ETA: 8:15 - loss: 2.3429 - categorical_accuracy: 0.2233167/765 [=====>........................] - ETA: 8:14 - loss: 2.3433 - categorical_accuracy: 0.2229168/765 [=====>........................] - ETA: 8:13 - loss: 2.3402 - categorical_accuracy: 0.2232169/765 [=====>........................] - ETA: 8:13 - loss: 2.3374 - categorical_accuracy: 0.2236170/765 [=====>........................] - ETA: 8:12 - loss: 2.3341 - categorical_accuracy: 0.2244171/765 [=====>........................] - ETA: 8:11 - loss: 2.3311 - categorical_accuracy: 0.2257172/765 [=====>........................] - ETA: 8:11 - loss: 2.3276 - categorical_accuracy: 0.2267173/765 [=====>........................] - ETA: 8:10 - loss: 2.3257 - categorical_accuracy: 0.2265174/765 [=====>........................] - ETA: 8:09 - loss: 2.3225 - categorical_accuracy: 0.2274175/765 [=====>........................] - ETA: 8:09 - loss: 2.3199 - categorical_accuracy: 0.2279176/765 [=====>........................] - ETA: 8:08 - loss: 2.3162 - categorical_accuracy: 0.2289177/765 [=====>........................] - ETA: 8:07 - loss: 2.3132 - categorical_accuracy: 0.2292178/765 [=====>........................] - ETA: 8:07 - loss: 2.3119 - categorical_accuracy: 0.2291179/765 [======>.......................] - ETA: 8:06 - loss: 2.3102 - categorical_accuracy: 0.2289180/765 [======>.......................] - ETA: 8:05 - loss: 2.3068 - categorical_accuracy: 0.2292181/765 [======>.......................] - ETA: 8:05 - loss: 2.3040 - categorical_accuracy: 0.2296182/765 [======>.......................] - ETA: 8:04 - loss: 2.3014 - categorical_accuracy: 0.2304183/765 [======>.......................] - ETA: 8:03 - loss: 2.2987 - categorical_accuracy: 0.2307184/765 [======>.......................] - ETA: 8:03 - loss: 2.2979 - categorical_accuracy: 0.2311185/765 [======>.......................] - ETA: 8:02 - loss: 2.2946 - categorical_accuracy: 0.2316186/765 [======>.......................] - ETA: 8:01 - loss: 2.2949 - categorical_accuracy: 0.2314187/765 [======>.......................] - ETA: 8:01 - loss: 2.2924 - categorical_accuracy: 0.2309188/765 [======>.......................] - ETA: 8:00 - loss: 2.2903 - categorical_accuracy: 0.2312189/765 [======>.......................] - ETA: 7:59 - loss: 2.2897 - categorical_accuracy: 0.2312190/765 [======>.......................] - ETA: 7:58 - loss: 2.2869 - categorical_accuracy: 0.2317191/765 [======>.......................] - ETA: 7:58 - loss: 2.2837 - categorical_accuracy: 0.2323192/765 [======>.......................] - ETA: 7:57 - loss: 2.2823 - categorical_accuracy: 0.2321193/765 [======>.......................] - ETA: 7:56 - loss: 2.2800 - categorical_accuracy: 0.2328194/765 [======>.......................] - ETA: 7:55 - loss: 2.2770 - categorical_accuracy: 0.2337195/765 [======>.......................] - ETA: 7:55 - loss: 2.2749 - categorical_accuracy: 0.2337196/765 [======>.......................] - ETA: 7:54 - loss: 2.2749 - categorical_accuracy: 0.2336197/765 [======>.......................] - ETA: 7:55 - loss: 2.2731 - categorical_accuracy: 0.2338198/765 [======>.......................] - ETA: 7:54 - loss: 2.2705 - categorical_accuracy: 0.2342199/765 [======>.......................] - ETA: 7:54 - loss: 2.2674 - categorical_accuracy: 0.2346200/765 [======>.......................] - ETA: 7:56 - loss: 2.2658 - categorical_accuracy: 0.2344201/765 [======>.......................] - ETA: 7:56 - loss: 2.2641 - categorical_accuracy: 0.2351202/765 [======>.......................] - ETA: 7:56 - loss: 2.2624 - categorical_accuracy: 0.2356203/765 [======>.......................] - ETA: 7:55 - loss: 2.2597 - categorical_accuracy: 0.2365204/765 [=======>......................] - ETA: 7:55 - loss: 2.2578 - categorical_accuracy: 0.2368205/765 [=======>......................] - ETA: 7:54 - loss: 2.2552 - categorical_accuracy: 0.2369206/765 [=======>......................] - ETA: 7:53 - loss: 2.2541 - categorical_accuracy: 0.2367207/765 [=======>......................] - ETA: 7:52 - loss: 2.2517 - categorical_accuracy: 0.2364208/765 [=======>......................] - ETA: 7:51 - loss: 2.2497 - categorical_accuracy: 0.2369209/765 [=======>......................] - ETA: 7:51 - loss: 2.2482 - categorical_accuracy: 0.2371210/765 [=======>......................] - ETA: 7:50 - loss: 2.2461 - categorical_accuracy: 0.2372211/765 [=======>......................] - ETA: 7:49 - loss: 2.2440 - categorical_accuracy: 0.2374212/765 [=======>......................] - ETA: 7:48 - loss: 2.2422 - categorical_accuracy: 0.2376213/765 [=======>......................] - ETA: 7:47 - loss: 2.2407 - categorical_accuracy: 0.2383214/765 [=======>......................] - ETA: 7:46 - loss: 2.2393 - categorical_accuracy: 0.2383215/765 [=======>......................] - ETA: 7:46 - loss: 2.2365 - categorical_accuracy: 0.2387216/765 [=======>......................] - ETA: 7:45 - loss: 2.2349 - categorical_accuracy: 0.2389217/765 [=======>......................] - ETA: 7:44 - loss: 2.2330 - categorical_accuracy: 0.2389218/765 [=======>......................] - ETA: 7:43 - loss: 2.2308 - categorical_accuracy: 0.2395219/765 [=======>......................] - ETA: 7:42 - loss: 2.2301 - categorical_accuracy: 0.2394220/765 [=======>......................] - ETA: 7:42 - loss: 2.2278 - categorical_accuracy: 0.2401221/765 [=======>......................] - ETA: 7:41 - loss: 2.2249 - categorical_accuracy: 0.2408222/765 [=======>......................] - ETA: 7:40 - loss: 2.2238 - categorical_accuracy: 0.2404223/765 [=======>......................] - ETA: 7:39 - loss: 2.2214 - categorical_accuracy: 0.2410224/765 [=======>......................] - ETA: 7:38 - loss: 2.2193 - categorical_accuracy: 0.2414225/765 [=======>......................] - ETA: 7:37 - loss: 2.2179 - categorical_accuracy: 0.2418226/765 [=======>......................] - ETA: 7:36 - loss: 2.2162 - categorical_accuracy: 0.2423227/765 [=======>......................] - ETA: 7:34 - loss: 2.2153 - categorical_accuracy: 0.2422228/765 [=======>......................] - ETA: 7:33 - loss: 2.2126 - categorical_accuracy: 0.2430229/765 [=======>......................] - ETA: 7:32 - loss: 2.2104 - categorical_accuracy: 0.2436230/765 [========>.....................] - ETA: 7:31 - loss: 2.2099 - categorical_accuracy: 0.2436231/765 [========>.....................] - ETA: 7:30 - loss: 2.2087 - categorical_accuracy: 0.2440232/765 [========>.....................] - ETA: 7:29 - loss: 2.2066 - categorical_accuracy: 0.2447233/765 [========>.....................] - ETA: 7:28 - loss: 2.2063 - categorical_accuracy: 0.2445234/765 [========>.....................] - ETA: 7:27 - loss: 2.2053 - categorical_accuracy: 0.2447235/765 [========>.....................] - ETA: 7:26 - loss: 2.2038 - categorical_accuracy: 0.2447236/765 [========>.....................] - ETA: 7:25 - loss: 2.2020 - categorical_accuracy: 0.2451237/765 [========>.....................] - ETA: 7:24 - loss: 2.2000 - categorical_accuracy: 0.2458238/765 [========>.....................] - ETA: 7:23 - loss: 2.1979 - categorical_accuracy: 0.2461239/765 [========>.....................] - ETA: 7:22 - loss: 2.1955 - categorical_accuracy: 0.2466240/765 [========>.....................] - ETA: 7:21 - loss: 2.1939 - categorical_accuracy: 0.2469241/765 [========>.....................] - ETA: 7:20 - loss: 2.1911 - categorical_accuracy: 0.2481242/765 [========>.....................] - ETA: 7:19 - loss: 2.1898 - categorical_accuracy: 0.2483243/765 [========>.....................] - ETA: 7:18 - loss: 2.1876 - categorical_accuracy: 0.2491244/765 [========>.....................] - ETA: 7:17 - loss: 2.1862 - categorical_accuracy: 0.2496245/765 [========>.....................] - ETA: 7:16 - loss: 2.1856 - categorical_accuracy: 0.2496246/765 [========>.....................] - ETA: 7:15 - loss: 2.1839 - categorical_accuracy: 0.2497247/765 [========>.....................] - ETA: 7:15 - loss: 2.1826 - categorical_accuracy: 0.2500248/765 [========>.....................] - ETA: 7:14 - loss: 2.1816 - categorical_accuracy: 0.2499249/765 [========>.....................] - ETA: 7:13 - loss: 2.1801 - categorical_accuracy: 0.2504250/765 [========>.....................] - ETA: 7:12 - loss: 2.1787 - categorical_accuracy: 0.2508251/765 [========>.....................] - ETA: 7:11 - loss: 2.1781 - categorical_accuracy: 0.2502252/765 [========>.....................] - ETA: 7:10 - loss: 2.1766 - categorical_accuracy: 0.2507253/765 [========>.....................] - ETA: 7:09 - loss: 2.1744 - categorical_accuracy: 0.2511254/765 [========>.....................] - ETA: 7:08 - loss: 2.1722 - categorical_accuracy: 0.2517255/765 [=========>....................] - ETA: 7:07 - loss: 2.1710 - categorical_accuracy: 0.2517256/765 [=========>....................] - ETA: 7:06 - loss: 2.1703 - categorical_accuracy: 0.2521257/765 [=========>....................] - ETA: 7:05 - loss: 2.1689 - categorical_accuracy: 0.2527258/765 [=========>....................] - ETA: 7:04 - loss: 2.1673 - categorical_accuracy: 0.2529259/765 [=========>....................] - ETA: 7:04 - loss: 2.1658 - categorical_accuracy: 0.2534260/765 [=========>....................] - ETA: 7:04 - loss: 2.1650 - categorical_accuracy: 0.2534261/765 [=========>....................] - ETA: 7:03 - loss: 2.1625 - categorical_accuracy: 0.2541262/765 [=========>....................] - ETA: 7:02 - loss: 2.1618 - categorical_accuracy: 0.2539263/765 [=========>....................] - ETA: 7:01 - loss: 2.1600 - categorical_accuracy: 0.2545264/765 [=========>....................] - ETA: 7:00 - loss: 2.1587 - categorical_accuracy: 0.2550265/765 [=========>....................] - ETA: 7:00 - loss: 2.1576 - categorical_accuracy: 0.2554266/765 [=========>....................] - ETA: 6:59 - loss: 2.1558 - categorical_accuracy: 0.2560267/765 [=========>....................] - ETA: 6:58 - loss: 2.1548 - categorical_accuracy: 0.2563268/765 [=========>....................] - ETA: 6:57 - loss: 2.1531 - categorical_accuracy: 0.2564269/765 [=========>....................] - ETA: 6:56 - loss: 2.1529 - categorical_accuracy: 0.2563270/765 [=========>....................] - ETA: 6:55 - loss: 2.1515 - categorical_accuracy: 0.2566271/765 [=========>....................] - ETA: 6:54 - loss: 2.1508 - categorical_accuracy: 0.2569272/765 [=========>....................] - ETA: 6:53 - loss: 2.1485 - categorical_accuracy: 0.2579273/765 [=========>....................] - ETA: 6:53 - loss: 2.1480 - categorical_accuracy: 0.2578274/765 [=========>....................] - ETA: 6:52 - loss: 2.1462 - categorical_accuracy: 0.2583275/765 [=========>....................] - ETA: 6:51 - loss: 2.1443 - categorical_accuracy: 0.2589276/765 [=========>....................] - ETA: 6:50 - loss: 2.1440 - categorical_accuracy: 0.2591277/765 [=========>....................] - ETA: 6:49 - loss: 2.1429 - categorical_accuracy: 0.2594278/765 [=========>....................] - ETA: 6:48 - loss: 2.1429 - categorical_accuracy: 0.2591279/765 [=========>....................] - ETA: 6:47 - loss: 2.1411 - categorical_accuracy: 0.2592280/765 [=========>....................] - ETA: 6:46 - loss: 2.1402 - categorical_accuracy: 0.2592281/765 [==========>...................] - ETA: 6:46 - loss: 2.1387 - categorical_accuracy: 0.2595282/765 [==========>...................] - ETA: 6:45 - loss: 2.1378 - categorical_accuracy: 0.2598283/765 [==========>...................] - ETA: 6:44 - loss: 2.1355 - categorical_accuracy: 0.2600284/765 [==========>...................] - ETA: 6:43 - loss: 2.1344 - categorical_accuracy: 0.2600285/765 [==========>...................] - ETA: 6:42 - loss: 2.1331 - categorical_accuracy: 0.2603286/765 [==========>...................] - ETA: 6:41 - loss: 2.1336 - categorical_accuracy: 0.2603287/765 [==========>...................] - ETA: 6:40 - loss: 2.1326 - categorical_accuracy: 0.2608288/765 [==========>...................] - ETA: 6:39 - loss: 2.1313 - categorical_accuracy: 0.2609289/765 [==========>...................] - ETA: 6:38 - loss: 2.1301 - categorical_accuracy: 0.2608290/765 [==========>...................] - ETA: 6:37 - loss: 2.1290 - categorical_accuracy: 0.2610291/765 [==========>...................] - ETA: 6:36 - loss: 2.1287 - categorical_accuracy: 0.2608292/765 [==========>...................] - ETA: 6:35 - loss: 2.1272 - categorical_accuracy: 0.2611293/765 [==========>...................] - ETA: 6:34 - loss: 2.1263 - categorical_accuracy: 0.2614294/765 [==========>...................] - ETA: 6:34 - loss: 2.1250 - categorical_accuracy: 0.2616295/765 [==========>...................] - ETA: 6:33 - loss: 2.1236 - categorical_accuracy: 0.2619296/765 [==========>...................] - ETA: 6:32 - loss: 2.1228 - categorical_accuracy: 0.2619297/765 [==========>...................] - ETA: 6:31 - loss: 2.1216 - categorical_accuracy: 0.2620298/765 [==========>...................] - ETA: 6:30 - loss: 2.1202 - categorical_accuracy: 0.2624299/765 [==========>...................] - ETA: 6:29 - loss: 2.1187 - categorical_accuracy: 0.2628300/765 [==========>...................] - ETA: 6:28 - loss: 2.1186 - categorical_accuracy: 0.2625301/765 [==========>...................] - ETA: 6:27 - loss: 2.1174 - categorical_accuracy: 0.2626302/765 [==========>...................] - ETA: 6:26 - loss: 2.1163 - categorical_accuracy: 0.2628303/765 [==========>...................] - ETA: 6:25 - loss: 2.1154 - categorical_accuracy: 0.2628304/765 [==========>...................] - ETA: 6:25 - loss: 2.1145 - categorical_accuracy: 0.2632305/765 [==========>...................] - ETA: 6:24 - loss: 2.1127 - categorical_accuracy: 0.2638306/765 [===========>..................] - ETA: 6:23 - loss: 2.1112 - categorical_accuracy: 0.2639307/765 [===========>..................] - ETA: 6:22 - loss: 2.1092 - categorical_accuracy: 0.2646308/765 [===========>..................] - ETA: 6:21 - loss: 2.1077 - categorical_accuracy: 0.2644309/765 [===========>..................] - ETA: 6:20 - loss: 2.1065 - categorical_accuracy: 0.2649310/765 [===========>..................] - ETA: 6:19 - loss: 2.1053 - categorical_accuracy: 0.2650311/765 [===========>..................] - ETA: 6:18 - loss: 2.1051 - categorical_accuracy: 0.2654312/765 [===========>..................] - ETA: 6:18 - loss: 2.1037 - categorical_accuracy: 0.2656313/765 [===========>..................] - ETA: 6:17 - loss: 2.1017 - categorical_accuracy: 0.2664314/765 [===========>..................] - ETA: 6:16 - loss: 2.1018 - categorical_accuracy: 0.2664315/765 [===========>..................] - ETA: 6:15 - loss: 2.1006 - categorical_accuracy: 0.2666316/765 [===========>..................] - ETA: 6:15 - loss: 2.0994 - categorical_accuracy: 0.2668317/765 [===========>..................] - ETA: 6:14 - loss: 2.0981 - categorical_accuracy: 0.2670318/765 [===========>..................] - ETA: 6:13 - loss: 2.0974 - categorical_accuracy: 0.2671319/765 [===========>..................] - ETA: 6:12 - loss: 2.0952 - categorical_accuracy: 0.2676320/765 [===========>..................] - ETA: 6:11 - loss: 2.0942 - categorical_accuracy: 0.2678321/765 [===========>..................] - ETA: 6:10 - loss: 2.0941 - categorical_accuracy: 0.2675322/765 [===========>..................] - ETA: 6:09 - loss: 2.0934 - categorical_accuracy: 0.2677323/765 [===========>..................] - ETA: 6:09 - loss: 2.0927 - categorical_accuracy: 0.2678324/765 [===========>..................] - ETA: 6:08 - loss: 2.0923 - categorical_accuracy: 0.2677325/765 [===========>..................] - ETA: 6:07 - loss: 2.0909 - categorical_accuracy: 0.2687326/765 [===========>..................] - ETA: 6:06 - loss: 2.0895 - categorical_accuracy: 0.2690327/765 [===========>..................] - ETA: 6:05 - loss: 2.0882 - categorical_accuracy: 0.2694328/765 [===========>..................] - ETA: 6:04 - loss: 2.0871 - categorical_accuracy: 0.2697329/765 [===========>..................] - ETA: 6:03 - loss: 2.0858 - categorical_accuracy: 0.2700330/765 [===========>..................] - ETA: 6:03 - loss: 2.0853 - categorical_accuracy: 0.2699331/765 [===========>..................] - ETA: 6:02 - loss: 2.0846 - categorical_accuracy: 0.2700332/765 [============>.................] - ETA: 6:01 - loss: 2.0839 - categorical_accuracy: 0.2698333/765 [============>.................] - ETA: 6:00 - loss: 2.0827 - categorical_accuracy: 0.2702334/765 [============>.................] - ETA: 5:59 - loss: 2.0818 - categorical_accuracy: 0.2702335/765 [============>.................] - ETA: 5:58 - loss: 2.0807 - categorical_accuracy: 0.2707336/765 [============>.................] - ETA: 5:57 - loss: 2.0797 - categorical_accuracy: 0.2709337/765 [============>.................] - ETA: 5:56 - loss: 2.0779 - categorical_accuracy: 0.2713338/765 [============>.................] - ETA: 5:55 - loss: 2.0772 - categorical_accuracy: 0.2713339/765 [============>.................] - ETA: 5:55 - loss: 2.0763 - categorical_accuracy: 0.2715340/765 [============>.................] - ETA: 5:54 - loss: 2.0751 - categorical_accuracy: 0.2719341/765 [============>.................] - ETA: 5:53 - loss: 2.0742 - categorical_accuracy: 0.2721342/765 [============>.................] - ETA: 5:52 - loss: 2.0728 - categorical_accuracy: 0.2726343/765 [============>.................] - ETA: 5:51 - loss: 2.0728 - categorical_accuracy: 0.2728344/765 [============>.................] - ETA: 5:50 - loss: 2.0722 - categorical_accuracy: 0.2729345/765 [============>.................] - ETA: 5:49 - loss: 2.0708 - categorical_accuracy: 0.2733346/765 [============>.................] - ETA: 5:48 - loss: 2.0704 - categorical_accuracy: 0.2730347/765 [============>.................] - ETA: 5:47 - loss: 2.0691 - categorical_accuracy: 0.2734348/765 [============>.................] - ETA: 5:46 - loss: 2.0679 - categorical_accuracy: 0.2736349/765 [============>.................] - ETA: 5:46 - loss: 2.0668 - categorical_accuracy: 0.2738350/765 [============>.................] - ETA: 5:45 - loss: 2.0652 - categorical_accuracy: 0.2744351/765 [============>.................] - ETA: 5:44 - loss: 2.0652 - categorical_accuracy: 0.2743352/765 [============>.................] - ETA: 5:43 - loss: 2.0645 - categorical_accuracy: 0.2745353/765 [============>.................] - ETA: 5:42 - loss: 2.0646 - categorical_accuracy: 0.2744354/765 [============>.................] - ETA: 5:41 - loss: 2.0633 - categorical_accuracy: 0.2752355/765 [============>.................] - ETA: 5:40 - loss: 2.0621 - categorical_accuracy: 0.2755356/765 [============>.................] - ETA: 5:39 - loss: 2.0605 - categorical_accuracy: 0.2760357/765 [=============>................] - ETA: 5:38 - loss: 2.0599 - categorical_accuracy: 0.2763358/765 [=============>................] - ETA: 5:38 - loss: 2.0591 - categorical_accuracy: 0.2765359/765 [=============>................] - ETA: 5:37 - loss: 2.0584 - categorical_accuracy: 0.2763360/765 [=============>................] - ETA: 5:36 - loss: 2.0576 - categorical_accuracy: 0.2763361/765 [=============>................] - ETA: 5:35 - loss: 2.0566 - categorical_accuracy: 0.2768362/765 [=============>................] - ETA: 5:34 - loss: 2.0556 - categorical_accuracy: 0.2768363/765 [=============>................] - ETA: 5:33 - loss: 2.0545 - categorical_accuracy: 0.2771364/765 [=============>................] - ETA: 5:32 - loss: 2.0542 - categorical_accuracy: 0.2771365/765 [=============>................] - ETA: 5:31 - loss: 2.0530 - categorical_accuracy: 0.2772366/765 [=============>................] - ETA: 5:31 - loss: 2.0522 - categorical_accuracy: 0.2775367/765 [=============>................] - ETA: 5:30 - loss: 2.0515 - categorical_accuracy: 0.2776368/765 [=============>................] - ETA: 5:29 - loss: 2.0507 - categorical_accuracy: 0.2779369/765 [=============>................] - ETA: 5:28 - loss: 2.0491 - categorical_accuracy: 0.2785370/765 [=============>................] - ETA: 5:27 - loss: 2.0479 - categorical_accuracy: 0.2789371/765 [=============>................] - ETA: 5:27 - loss: 2.0474 - categorical_accuracy: 0.2788372/765 [=============>................] - ETA: 5:26 - loss: 2.0461 - categorical_accuracy: 0.2790373/765 [=============>................] - ETA: 5:25 - loss: 2.0452 - categorical_accuracy: 0.2789374/765 [=============>................] - ETA: 5:25 - loss: 2.0438 - categorical_accuracy: 0.2792375/765 [=============>................] - ETA: 5:24 - loss: 2.0430 - categorical_accuracy: 0.2792376/765 [=============>................] - ETA: 5:23 - loss: 2.0423 - categorical_accuracy: 0.2793377/765 [=============>................] - ETA: 5:22 - loss: 2.0412 - categorical_accuracy: 0.2794378/765 [=============>................] - ETA: 5:21 - loss: 2.0418 - categorical_accuracy: 0.2793379/765 [=============>................] - ETA: 5:21 - loss: 2.0420 - categorical_accuracy: 0.2793380/765 [=============>................] - ETA: 5:20 - loss: 2.0415 - categorical_accuracy: 0.2792381/765 [=============>................] - ETA: 5:19 - loss: 2.0407 - categorical_accuracy: 0.2796382/765 [=============>................] - ETA: 5:18 - loss: 2.0402 - categorical_accuracy: 0.2798383/765 [==============>...............] - ETA: 5:17 - loss: 2.0402 - categorical_accuracy: 0.2799384/765 [==============>...............] - ETA: 5:16 - loss: 2.0390 - categorical_accuracy: 0.2802385/765 [==============>...............] - ETA: 5:16 - loss: 2.0377 - categorical_accuracy: 0.2808386/765 [==============>...............] - ETA: 5:15 - loss: 2.0362 - categorical_accuracy: 0.2813387/765 [==============>...............] - ETA: 5:14 - loss: 2.0348 - categorical_accuracy: 0.2816388/765 [==============>...............] - ETA: 5:13 - loss: 2.0351 - categorical_accuracy: 0.2815389/765 [==============>...............] - ETA: 5:12 - loss: 2.0344 - categorical_accuracy: 0.2813390/765 [==============>...............] - ETA: 5:11 - loss: 2.0338 - categorical_accuracy: 0.2815391/765 [==============>...............] - ETA: 5:10 - loss: 2.0330 - categorical_accuracy: 0.2816392/765 [==============>...............] - ETA: 5:10 - loss: 2.0330 - categorical_accuracy: 0.2816393/765 [==============>...............] - ETA: 5:09 - loss: 2.0322 - categorical_accuracy: 0.2820394/765 [==============>...............] - ETA: 5:08 - loss: 2.0312 - categorical_accuracy: 0.2821395/765 [==============>...............] - ETA: 5:07 - loss: 2.0305 - categorical_accuracy: 0.2824396/765 [==============>...............] - ETA: 5:06 - loss: 2.0296 - categorical_accuracy: 0.2826397/765 [==============>...............] - ETA: 5:06 - loss: 2.0297 - categorical_accuracy: 0.2823398/765 [==============>...............] - ETA: 5:05 - loss: 2.0282 - categorical_accuracy: 0.2827399/765 [==============>...............] - ETA: 5:04 - loss: 2.0277 - categorical_accuracy: 0.2830400/765 [==============>...............] - ETA: 5:04 - loss: 2.0271 - categorical_accuracy: 0.2831401/765 [==============>...............] - ETA: 5:03 - loss: 2.0264 - categorical_accuracy: 0.2832402/765 [==============>...............] - ETA: 5:02 - loss: 2.0256 - categorical_accuracy: 0.2836403/765 [==============>...............] - ETA: 5:01 - loss: 2.0253 - categorical_accuracy: 0.2833404/765 [==============>...............] - ETA: 5:00 - loss: 2.0247 - categorical_accuracy: 0.2833405/765 [==============>...............] - ETA: 4:59 - loss: 2.0243 - categorical_accuracy: 0.2833